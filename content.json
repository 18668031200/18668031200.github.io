{"pages":[],"posts":[{"title":"monotonous","text":"Spring Event 关于ContextStartedEvent 使用 问题 在spring boot 中定义event listener 实现ContextStartedEventListener 监听上下文启动实现.发现项目启动后项目并不会打印出我们所需要的日志 ContextStartedEventListener.java12345678910111213@Componentpublic class ContextStartedEventListener implements ApplicationListener&lt;ContextStartedEvent&gt; { private static final Logger log = LoggerFactory.getLogger(ContextStartedEventListener.class); @Override public void onApplicationEvent(ContextStartedEvent event) { log.info(\"ContextStartedEventListener : 项目启动\"); }} 解析 打开spring 源码发现在AbstractApplicationContext#start() 方法中调用了此方法。 ContextStoppedEvent同理也是stop方法。 AbstractApplicationContext.java12345678910111213@Overridepublic void start() { getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));}@Overridepublic void stop() { getLifecycleProcessor().stop(); publishEvent(new ContextStoppedEvent(this));} 定位到调用该方法的地方为DefaultLifecycleProcessor#start(). 很明显是在生命周期的处理器中调用。再次定位调用这个start方法的来源。 AbstractApplicationContext.java12345678 @Overridepublic void start() { getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));} 结论我们一般启动spring boot 是使用AbstractApplicationContext#refresh方法而不是start()方法，所以这里只能使用abstractApplicationContext 的start方法启动上下文是才会产生这个事件。 后记在DefaultLifecycleProcessor中使用spring boot 启动使用的是 DefaultLifecycleProcessor.java12345@Override public void onRefresh() { startBeans(true); this.running = true; } 他和刚刚的abstrctApplicationContext调用地start方法只有一个参数autoStartupOnly的区别。这个参数为false时即我们abstrctApplicationContext.start时可以在我们的lifecycle bean 上使用注解@Phase 定义生命周期的阶段，从而自定义lifecycle bean 的start顺序。 这个注解还和timeoutPerShutdownPhase这个产数有关，timeoutPerShutdownPhase定义了lifecycle bean stop的超时时间DefaultLifecycleProcessor.java1234567891011121314151617181920212223242526public void stop() { if (this.members.isEmpty()) { return; } this.members.sort(Collections.reverseOrder()); CountDownLatch latch = new CountDownLatch(this.smartMemberCount); Set&lt;String&gt; countDownBeanNames = Collections.synchronizedSet(new LinkedHashSet&lt;&gt;()); Set&lt;String&gt; lifecycleBeanNames = new HashSet&lt;&gt;(this.lifecycleBeans.keySet()); for (LifecycleGroupMember member : this.members) { if (lifecycleBeanNames.contains(member.name)) { doStop(this.lifecycleBeans, member.name, latch, countDownBeanNames); } else if (member.bean instanceof SmartLifecycle) { // Already removed: must have been a dependent bean from another phase latch.countDown(); } } try { latch.await(this.timeout, TimeUnit.MILLISECONDS); } catch (InterruptedException ex) { Thread.currentThread().interrupt(); } } 」","link":"/2021/05/14/ContextStartedEvent/"},{"title":"mysql8","text":"mysql 8 新特性mysql分库分表并不是一定从性能的角度上需求，大部分场景是为了更好的管理数据 数据量大时需要对数据进行新加字段进行加以归类标记，DDL会锁表导致长时间堵塞。(mysql 8 特性会大幅度缩短这个时间，同时mysql 8增加了备份锁，减少备份的时间) 当一张表或者一个库出现问题时不会导致整个应用不能访问db. 灰度？数据库性能。 WHERE 语句内使用函数走索引select * from x where YEAR(date) = 2021 降序索引 mysql索引以前一直都是顺序，现在可以按降序存储。 index idx_c1_c2(c1,c2 desc)在索引反向扫描是 explain 语句extra中会显示Backward index scan GROUP BY 语句不在隐式排序现在select group by 语句不会按照group by 字段进行隐式排序mysql 5x 中explain 语句的extra 中有Using filesort 在高并发的情况下性能提升在高并发的情况下，只读和更新操作性能提升 默认字符集为utf8mb4修改默认字符集，同时查询性能增加 增加SKIP LOCKED 和NOWAITselect from x where id = 1 for update skip lockedselect from x where id = 1 for update skip nowait 前者查询加锁的记录被其他线程持有锁时会直接返回空。后者查询加锁的记录被其他线程持有锁时会直接报错。在高并发下比如抢红包等场景下使用。 文档数据库mysql 支持nosql的crud.同时提供了JSON函数 新增统计函数和GIS窗口函数。(不常用)GIS 地理信息(不常用) DDL 原子性数据字典集中存储，增强crash safe能力。 MGR 增强MGR 集群的健壮和稳定性加强。","link":"/2021/07/15/mysql8/"},{"title":"LINUX I/O 简介","text":"LINUX I/O 简介在linux中所有外部设备，进程，网络都可以看成一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个file descriptor(fd,文件描述符)。对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符)，描述符就是一个数字，它指向内核中的一个结构体（文件路径，数据区等一些属性）。 ####基本I/O与标准I/O 类unix系统中有直接对文件进行的操作函数read()/write()，这些被称为不带缓冲的I/O；标准I/O在基本的I/O函数基础上增加了流和缓冲的概念，常用的函数有fopen/getc()/putc()等，标准I/O使用了缓冲的机制，缓冲又分为全缓冲和行缓冲，引入缓冲机制主要是为了提供文件读写的性能和效率。 读文件调用getc()时,操作系统底层会使用read()函数，并从用户空间切换到内核空间，执行系统调用。首先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，经过两次数据拷贝过程，进程才能获取到文件内容。写操作也是一样，用户态写数据时，待发送数据所在的缓冲区处于内核空间，用户态不能直接访问，必须先拷贝至内核空间对应的主存，才能写回磁盘中（延迟写回），因此写入也是需要两次数据拷贝。 ####I/O模型 I/O阻塞模型 默认情况下，我们使用的都是阻塞I/O模型，在缺省情况下所有对文件的操作都是阻塞的。以套接字为例，在进程空间中调用recvfrom. If no messages are available at the socket, the receive calls wait for a message to arrive, unless the socket is nonblocking (see fcntl(2)), in which case the value -1 is returned and the external variable errno is set to EAGAIN or EWOULDBLOCK. 他会去等待信息返回且被复制到应用进程的缓冲区内或者发送错误并且发送到EAGAIN or EWOULDBLOCK. ，进程会在此期间一直等待。 非阻塞I/O模型 非阻塞IO模型下，我们发出open/read/write这样的IO操作时，这些操作不会永远阻塞，而是立即返回。对于一个给定的文件描述符，有两种指定非阻塞的方法： 1.调用open获得描述符时，可指定O_NONBLOCK标志。 2.对于一个已经打开的描述符，可调用fcntl，由该函数打开O_NONBLOCK状态标志。 非阻塞模型由于立即返回，后面需要轮询不断的查看读写是否已经就绪，然后才能进行I/O操作 IO复用 Linux 提供select/poll,进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select操作上，这样select/poll可以帮我们侦测多个fd是否处于就绪状态。缺点：受FD_SETSIZE大小影响，优点：Linux 提供epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描,性能更高。 信号驱动I/O 需要开启套接口信号驱动I/O功能，系统通过调用sigaction执行一个信号处理函数（此系统调用立即返回，非阻塞）。当数据返回时生成一个SIGIO，通过信号回调通知应用系统调用recvfrom读取数据。 异步I/O 告知kernel启动某个操作，并让kernel在完成整个操作后（包括将数据从kernel复制到用户自己的缓存区）进行通知，与信号驱动模型的主要区别是信号驱动I/O有kernel通知何时开始，而异步I/O有kernel通知何时完成。 ####epoll epoll在2.5.44内核中被引进,epoll与select的原理比较相似，主要因为select一些固有的缺陷所有linux使用了epoll来代替select.而除了epoll，在freeBSD下还有kqueue,Solaris的/dev/poll.epoll 在文件描述符可进行 I/O 操作时进行通知，而 kqueue 和 IOCP 都在请求的操作完成时进行通知。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 ######epoll的优点 支持一个进程打开的socket描述符（fd）不受FD_SETSIZE限制(仅受限与操作系统的最大文件句柄数) I/O效率不会随着FD的数目的增加而线性下降 使用mmap加速内核与用户空间的消息传递（mmap是一种内存映射文件的方法，可以将一个文件或者其它对象映射到进程的虚拟地址空间，实现文件磁盘地址和进程虚拟地址空间中某一段地址的一一对映，这样应用程序就可以通过访问进程虚拟内存地地址直接访问到文件或对象。） epoll的api更加简单 来源netty netty权威指南","link":"/2019/04/18/year-month-day-LinuxIO-md/"},{"title":"icarus-bug","text":"##记一次hexo切换主题icarus排版混乱的bug ######起因 第一次使用hexo搭建blog,看到icarus主题漂亮就入了坑，本地运行完美。仿照国内教程各种详细的配置。 http://blog.kimzing.com/ 准备remote上传 1sudo hexo d -g 一切ok,打开网站却发现左边的介绍去了中间，样式全无。按F12查看控制台发现并没有脚本或者css报错信息，只能google. 搜索内容如下 1.查看css文件完整性 打开F12对比发现完全一下 2.修改根目录下的url 设置完发现无用 ######结果 在下面helloworld中发现了类似图片404的图片，于是就想着先删除它，在本地rm helloworld.md后 12sudo hexo gsudo hexo d hellowold 没删掉 排版好了。。。","link":"/2019/04/18/icarus-bug/"},{"title":"monotonous","text":"单调栈结构问题给定一个不含有重复值的数组arr,找到每一个i位置左边和右边离i位置最近且值比arr[i]小的位置，返回所有位置相应的信息。时间复杂度 O（N）。 举例arr = [3,4,1,5,6,2,7] 返回数组 [[-1,2],[0,2],[-1,-1],[2,5],[3,5],[2,-1],[5,-1]] -1表示不存在。 解答准备一个栈 stack, 栈中存放数组中的元素，初始化stack为空。如果要求找到每一个i位置左边和右边离i位置最近且值比arr[i]小的位置，就么就需要然stack从栈顶到栈底的位置所代表的元素值必须是严格递减的，反之亦然。这里是递减。 初始化arr = [3,4,1,5,6,2,7],stack = {}. 遍历到arr[0] == 3, i == 0,发现stack为空，将 位置0 入栈 ,stack变为 {0(3)}. 遍历到arr[1] == 4, 发现将 1（4）放入stack不会破坏stack从栈顶到栈底严格递减，直接放入. stack变为 {1(4),0(3)} 遍历到arr[2] == 1, i == 2 发现将 2（1）放入stack会破坏严格递减的规则，所以从stack的栈顶开始弹出元素。如果x位置被弹出，在栈中位于x位置下面的位置就是左边离x位置最近且比arr[x]小的位置，i 就是x位置右边离x位置最近且比arr[x]小的位置。所以ans[1] = [0, 2].弹出x(1)后发现放入位置2（1）还是会破坏严格递减的规则，所以弹出0（3），因为stack在0（3）下面没有元素了，说明在位置0（3）左边没有存在比它还小的元素，所以ans[0] = [-1, 2].此时stack 为空，将2（1）压入stack. 遍历到arr[3] == 5 ,发现arr[3] &gt; arr[2], 直接放入3（5）， stack依次为{3(5), 2(1)} 遍历到arr[4] == 6 ,同上放入， stack依次为{4(6), 3(5), 2(1)} 遍历到arr[5] == 2, 因为放入会破坏单调递减， 依次弹出4(6), 3(5)， 位置4下面是3，所以ans[4] = {3,5},位置3下面是位置2， 所以ans[3] = {2,5}. 最后放入5(2)， stack依次为{5(2), 2(1)} 遍历到 arr[6] == 7, 直接放入stack ，stack依次为{6(7), 5(2), 2(1)} 遍历阶段结束后，清算栈中剩下的位置。因为是清算过程中，所以数组中不存在在右边比它们小的元素，所以ans[x] = {?, -1} 弹出位置6， 栈中它下面的位置是5(2), 所以ans[6] = {5, -1}弹出位置5， 栈中它下面的位置是2(1), 所以ans[6] = {2, -1}最后只剩下2(1)，因为栈中已经没有元素了，所以ans[2] = {-1,-1}至此全部完成，整个流程中，每个位置都进栈一次，出栈一次，所以整个流程的时间复杂度为O（N） 重复问题当数组中的元素允许重复时，元素（位置）入栈时不变，如果值相同则将位置替换。 代码solution.java123456789101112131415161718192021222324public int[][] getNearLessNoRepeat(int[] arr){ int[][] res = new int[arr.length][2]; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) { while (!stack.empty() &amp;&amp; arr[stack.peek()] &gt; arr[i]){ int a = stack.pop(); int left = stack.isEmpty() ? -1 : stack.peek(); res[a][0] = left; res[a][1] = i; } stack.push(i); } //遍历完 while (!stack.isEmpty()){ int a = stack.pop(); int left = stack.isEmpty() ? -1 : stack.peek(); res[a][0] = left; res[a][1] = -1; } return res; } 来源左程云 《程序员算法面试指南》","link":"/2019/05/06/monotonous/"},{"title":"zsh","text":"###zsh 从 macOS Catalina 版开始，您的 Mac 将使用 zsh 作为默认登录 Shell 和交互式 Shell。您还可以在较低版本的 macOS 中将 zsh 设置为默认 Shell。 默认情况下，您的 Mac 使用 zsh 或 bash 作为登录 Shell 和交互式 Shell 的命令行解释器： 从 macOS Catalina Beta 版开始，zsh (Z shell) 是所有新建用户帐户的默认 Shell。bash 是 macOS Mojave 及更低版本中的默认 Shell。zsh 与 Bourne Shell (sh) 高度兼容，并且与 bash 基本兼容，但存在一些差别。要进一步了解 zsh 及其全面的命令行完成系统，请在“终端”中输入 man zsh。 在mac中打卡控制台会出现The default interactive shell is now zsh.To update your account to use zsh, please run chsh -s /bin/zsh.For more details, please visit https://support.apple.com/kb/HT208050. 打卡网址发现新添加了.zprofile 和 .zshrc那已经有了bash 为什么需要zsh? ######Licensing google了一下发现https://thenextweb.com/dd/2019/06/04/why-does-macos-catalina-use-zsh-instead-of-bash-licensing/ 里提到苹果好像是为了更换里面的licensing。原来用的是GUN的bash，协议GPLv3。 同时苹果可能会开始维护更新这个zsh了。","link":"/2019/10/14/zsh/"},{"title":"spring security 1 配置类加载","text":"##spring security 配置类加载 ####WebSecurityConfigurerAdapter 一般我们在使用spring security作为我们安全验证的时候经常会编写配置类继承WebSecurityConfigurerAdapter，通过重写其中的config()类来自定义自己的安全验证流程。而HttpSecurity类则是其中非常重要的一个配置类，通过它你可以集成其他第三方的生态来满足自己的业务需求。 ####HttpSecurity 在HttpSecurity 中我们可以看到很多配置方法比如 HttpSecurit.java1234567891011public OpenIDLoginConfigurer&lt;HttpSecurity&gt; openidLogin() throws Exception { return getOrApply(new OpenIDLoginConfigurer&lt;&gt;()); } ...public HeadersConfigurer&lt;HttpSecurity&gt; headers() throws Exception { return getOrApply(new HeadersConfigurer&lt;&gt;()); } 很明显它们都调用了getOrAppley方法 HttpSecurit.java123456789101112private &lt;C extends SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt;&gt; C getOrApply( C configurer) throws Exception { //从已加载中的配置类根据class获取 C existingConfig = (C) getConfigurer(configurer.getClass()); //不为空的或就返回已加载类 if (existingConfig != null) { return existingConfig; } return apply(configurer); } 再看apply这个方法 AbstractConfiguredSecurityBuilder123456789101112public &lt;C extends SecurityConfigurerAdapter&lt;O, B&gt;&gt; C apply(C configurer) throws Exception { //添加后置处理器 configurer.addObjectPostProcessor(objectPostProcessor); //设置builder configurer.setBuilder((B) this); //把这个配置类添加到配置类集合中 add(configurer); return configurer; } 首先objectPostProcessor 应该是ObjectPostProcessorConfiguration这个配置类中的AutowireBeanFactoryObjectPostProcessor实例，它管理了一系列的SmartInitializingSingleton的afterSingletonsInstantiated方法和DisposableBean的destroy方法，以确保他们被调用。 configurer.setBuilder((B) this); 则是把builder类的引用放到配置类中（SecurityConfigurerAdapter子类）这样配置类就可以通过getbuilder()方法来实现一系列操作。 最后configer会被放入一个集合中通过doBuild()方法来进行加载初始化 AbstractConfiguredSecurityBuilder1234567891011121314151617181920212223242526protected final O doBuild() throws Exception { //加锁 synchronized (configurers) { buildState = BuildState.INITIALIZING; beforeInit(); init(); buildState = BuildState.CONFIGURING; beforeConfigure(); configure(); buildState = BuildState.BUILDING; O result = performBuild(); buildState = BuildState.BUILT; return result; } } 各种配置类有各自的实现，这样ss就可以扩展安全验证的机制了。","link":"/2019/04/22/ss-config1/"},{"title":"DirectByteBuffer","text":"堆外内存DirectByteBufferDirectByteBuffer是jdk提供的访问对外内存的一种实现，堆外内存的优势在于，1.使用socket网络传输时，它能够节省堆内存到堆外内存的复制消耗。2.对于磁盘io,可以使用内存映射，提高效率。3.不需要考虑gc问题。它并不受jvm内存管理,所有当对外内存不足时，系统会显式地调用一次System.gc()，如果还是不能申请到足够内存，系统就会报出 12java.lang.OutOfMemoryError: Direct buffer memory 如果我们在jvm参数上加上 -XX:+DisableExplicitGC 那么就会使显式gc无效。同时我们也可以通过增大-XX:MaxDirectMemorySize来增加堆外内存 下面看一下DirectByteBuffer的创建DirectByteBuffer.java1234567891011121314151617181920212223242526272829303132333435DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); //是否对齐 boolean pa = VM.isDirectMemoryPageAligned(); //默认每页的大小 int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); //在申请或者释放内存时都应该调用 里面通过CAS来count //在这个方法中 如果检测到内存不够就会显式调用system.gc() Bits.reserveMemory(size, cap); long base = 0; try { //调用jni申请内存 base = UNSAFE.allocateMemory(size); } catch (OutOfMemoryError x) { //cas 减少数量 Bits.unreserveMemory(size, cap); throw x; } UNSAFE.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); } else { address = base; } //添加cleaner 用于回收内存 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; 在看下Cleaner,它继承了PhantomReference。 PhantomReference的作用在于跟踪垃圾回收过程 Phantom reference objects, which are enqueued after the collector determines that their referents may otherwise be reclaimed. Reference中有个ReferenceHandler 它会一直检测getAndClearReferencePendingList()获得的list, Reference.java1234567891011121314151617181920212223242526272829303132333435363738private static void processPendingReferences() { // Only the singleton reference processing thread calls // waitForReferencePendingList() and getAndClearReferencePendingList(). // These are separate operations to avoid a race with other threads // that are calling waitForReferenceProcessing(). waitForReferencePendingList(); Reference&lt;Object&gt; pendingList; synchronized (processPendingLock) { pendingList = getAndClearReferencePendingList(); processPendingActive = true; } while (pendingList != null) { Reference&lt;Object&gt; ref = pendingList; pendingList = ref.discovered; ref.discovered = null; //这里如果ref是Cleaner 就会调用它的clean()方法 if (ref instanceof Cleaner) { ((Cleaner)ref).clean(); // Notify any waiters that progress has been made. // This improves latency for nio.Bits waiters, which // are the only important ones. synchronized (processPendingLock) { processPendingLock.notifyAll(); } } else { ReferenceQueue&lt;? super Object&gt; q = ref.queue; if (q != ReferenceQueue.NULL) q.enqueue(ref); } } // Notify any waiters of completion of current round. synchronized (processPendingLock) { processPendingActive = false; processPendingLock.notifyAll(); } } 而cleaner会调用Deallocator里面的 DirectByteBuffer.java1234567891011public void run() { if (address == 0) { // Paranoia return; } //释放内存 UNSAFE.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); } netty堆外内存AbstractByteBufAllocator protected abstract ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity); 在它的实现里有池化和非池化，这里主要介绍池化策略。 PooledByteBufAllocatorPooledByteBufAllocator采用的是jemalloc来进行内存分配。jemalloc将内存划分为一个个Arena，而在PooledByteBufAllocator里面，程序维护了heapArenas和directArenas，分别代表堆内和堆外Arena。每个Arena又有多个chunk组成。可以看到PoolArena中有PoolChunkList - 存储chunk，SizeClass枚举类 - 对分配内存的大小作区分，tinySubpagePools - 用来保存为tiny规格分配的内存页的链表， smallSubpagePools -用来保存为small规格分配的内存页的链表。 PooledByteBufAllocator.java123456789101112131415161718@Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) { PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena; final ByteBuf buf; if (directArena != null) { //分配内存 buf = directArena.allocate(cache, initialCapacity, maxCapacity); } else { buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); } return toLeakAwareBuffer(buf); } PoolArena.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T&gt; buf, final int reqCapacity) { //计算大小 final int normCapacity = normalizeCapacity(reqCapacity); //根据大小选择不同的PoolSubpage 和 allocate if (isTinyOrSmall(normCapacity)) { // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T&gt;[] table; boolean tiny = isTiny(normCapacity); if (tiny) { // &lt; 512 //具体allocate if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } //计算出索引 tableIdx = tinyIdx(normCapacity); table = tinySubpagePools; } else { if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } tableIdx = smallIdx(normCapacity); table = smallSubpagePools; } //准备放到对应的page数组中 final PoolSubpage&lt;T&gt; head = table[tableIdx]; /** * Synchronize on the head. This is needed as {@link PoolChunk#allocateSubpage(int)} and * {@link PoolChunk#free(long)} may modify the doubly linked list as well. */ synchronized (head) { final PoolSubpage&lt;T&gt; s = head.next; if (s != head) { assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle &gt;= 0; s.chunk.initBufWithSubpage(buf, null, handle, reqCapacity); incTinySmallAllocation(tiny); return; } } synchronized (this) { allocateNormal(buf, reqCapacity, normCapacity); } incTinySmallAllocation(tiny); return; } if (normCapacity &lt;= chunkSize) { //在缓存外分配 if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } synchronized (this) { allocateNormal(buf, reqCapacity, normCapacity); ++allocationsNormal; } } else { // Huge allocations are never served via the cache so just call allocateHuge allocateHuge(buf, reqCapacity); } } 我们可以看到分配内存的信息会被保存在Aerna的chunk和page对应链表中。同时它会根据请求分配的大小选择不同的chunk和page. 参考堆外内存之 DirectByteBuffer 详解 涤生","link":"/2019/04/28/DirectByteBuffer/"},{"title":"rocketmq1","text":"rocketmq namesrvNamesrv简介namesrc 即 NameServer,类似于服务注册中心，它是RocketMq的调度中心，它提供了路由管理，服务注册及服务发现，服务剔除等服务。正是由于它，系统可以迅速地感知消息服务器的健康状况，对消息服务器的单点故障做出反应防止整个系统瘫痪。它还可以对消息进行负载均衡处理防止Broker宕机。 启动NamesrvNamesrvStartup.java123456789101112131415161718public static NamesrvController main0(String[] args) { try { NamesrvController controller = createNamesrvController(args); start(controller); String tip = \"The Name Server boot success. serializeType=\" + RemotingCommand.getSerializeTypeConfigInThisServer(); log.info(tip); System.out.printf(\"%s%n\", tip); return controller; } catch (Throwable e) { e.printStackTrace(); System.exit(-1); } return null; } 第一行createNamesrvController(args)根据参数创建一个NamesrvController实例，然后就这个实例当做参数调用start()方法，最后输出日志。先看start(final NamesrvController controller)方法 NamesrvStartup.java12345678910111213141516171819public static NamesrvController start(final NamesrvController controller) throws Exception {...boolean initResult = controller.initialize();...Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() { @Override public Void call() throws Exception { controller.shutdown(); return null; } })); controller.start(); return controller; } 可以看到它先调用了controller.initialize();这个条语句。然后给系统增加了一个关闭的钩子 在系统关闭之前回去调用controller的shutdown()方法。最后调用controller.start(). 可以看出这个NamesrvController就是整个启动过程关键类，而createNamesrvController(args)是生成它的方法。 NamesrvStartup.java123456789101112131415161718192021222324252627282930313233...//首先解析命令Options options = ServerUtil.buildCommandlineOptions(new Options()); commandLine = ServerUtil.parseCmdLine(\"mqnamesrv\", args, buildCommandlineOptions(options), new PosixParser()); ...//生成业务配置实例final NamesrvConfig namesrvConfig = new NamesrvConfig();//生成netty远程通信配置实例final NettyServerConfig nettyServerConfig = new NettyServerConfig();...//命令上-c 参数 系统会去读取配置文件并设置到NamesrvConfig中if (commandLine.hasOption('c')) {InputStream in = new BufferedInputStream(new FileInputStream(file));...namesrvConfig.setConfigStorePath(file);}//-p 参数也会设置if (commandLine.hasOption('p')) {...}...//logback 设置JoranConfigurator configurator = new JoranConfigurator();configurator.doConfigure(namesrvConfig.getRocketmqHome() + \"/conf/logback_namesrv.xml\");...最后生成NamesrvController 实例final NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig); // remember all configs to prevent discardcontroller.getConfiguration().registerConfig(properties); 可以看到NamesrvController 中有2个关键的配置类。 NamesrvConfig和NettyServerConfigNamesrvConfig。一个业务配置类，在类中有rocketmqHome（根目录，通过读取环境变量来设置）kvConfigPath 对应 kvConfig.json，NameServer存储KV配置属性的持久化路径。configStorePath 对应namesrv.properties，nameServer默认配置文件路径。orderMessageEnable，是否支持顺序消息，默认不支持。productEnvName 生产环境名称 NettyServerConfig。通信配置类listenPort：netty监听端口serverWorkerThreads： netty业务线程池数量serverCallbackExecutorThreads： netty public 任务线程池线程个数，默认为4个。用于处理消息发送，心跳检测等。serverSelectorThreads： IO线程池线程个数，主要是NameServer、Broker端解析请求的线程个数，这类线程主要是处理网络请求，解析请求包，然后转发到个业务线池完成具体的业务操作，然后将结果返回调用方。serverOnewaySemaphoreValue：send oneway 消息请求并发度（Broker端参数）serverAsyncSemaphoreValue：异步消息发送最大并发度（Boreker端参数）serverChannelMaxIdleTimeSeconds：网络连接最大空闲时间，默认120s。如果连接空闲时间超过该参数设置的值，连接将关闭。serverSocketSndBufSize：网络socket发送缓冲区大小，默认64k。serverSocketRcvBufSize：网络socket接受缓冲区大小，默认64k。serverPooledByteBufAllocatorEnable： ByteBuffer是否开启缓存，建议开启useEpollNativeSelector：是否启用Epoll IO模型，Linux环境建议开启。 NamesrvControllerNameServer控制类。里面包含了很多重要的配置和管理信息。前面通过namesrvConfig 和nettyServerConfig 初始化了一个NamesrvController实例。 NamesrvController.java12345678910111213this.namesrvConfig = namesrvConfig; this.nettyServerConfig = nettyServerConfig; this.kvConfigManager = new KVConfigManager(this); this.routeInfoManager = new RouteInfoManager(); this.brokerHousekeepingService = new BrokerHousekeepingService(this); this.configuration = new Configuration( log, this.namesrvConfig, this.nettyServerConfig ); this.configuration.setStorePathFromConfig(this.namesrvConfig, \"configStorePath\"); 这里还生成了一个路由信息管理类，一个broker下线的监听业务类BrokerHousekeepingService，用于连接改变时去更改this.routeInfoManager的路由信息。 ######RouteInfoManager的路由信息 RouteInfoManager.java12345678private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; topicQueueTable：Topic消息队列路由信息，消息发送时根据路由表进行负载均衡。brokerAddrTable：Broker基础信息，包含brokerName,所属集群名称，主备broker地址。clusterAddrTable：Broker集群信息，存储集群中所有的Broker名称。brokerLiveTable：Broker存活信息，NameServer每次收到心跳包时都会更新该信息。filterServerTable：过滤器列表。 而RouteInfoManager还拥有BrokerHousekeepingService的具体实现。 比如关闭连接 BrokerHousekeepingService.java1234@Override public void onChannelClose(String remoteAddr, Channel channel) { this.namesrvController.getRouteInfoManager().onChannelDestroy(remoteAddr, channel); } RouteInfoManager.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public void onChannelDestroy(String remoteAddr, Channel channel) { String brokerAddrFound = null; if (channel != null) { try { try { //获取读锁找到具体的broker信息 this.lock.readLock().lockInterruptibly(); Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; itBrokerLiveTable = this.brokerLiveTable.entrySet().iterator(); while (itBrokerLiveTable.hasNext()) { Entry&lt;String, BrokerLiveInfo&gt; entry = itBrokerLiveTable.next(); //找到 if (entry.getValue().getChannel() == channel) { brokerAddrFound = entry.getKey(); break; } } } finally { //解锁 this.lock.readLock().unlock(); } } catch (Exception e) { log.error(\"onChannelDestroy Exception\", e); } } if (null == brokerAddrFound) { brokerAddrFound = remoteAddr; } else { log.info(\"the broker's channel destroyed, {}, clean it's data structure at once\", brokerAddrFound); } if (brokerAddrFound != null &amp;&amp; brokerAddrFound.length() &gt; 0) { try { try { //加写锁，此时只有其余线程阻塞 this.lock.writeLock().lockInterruptibly(); //删除存活信息和对应的过滤器 this.brokerLiveTable.remove(brokerAddrFound); this.filterServerTable.remove(brokerAddrFound); String brokerNameFound = null; boolean removeBrokerName = false; //寻找对应的基础信息 Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable = this.brokerAddrTable.entrySet().iterator(); while (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) { BrokerData brokerData = itBrokerAddrTable.next().getValue(); Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator(); while (it.hasNext()) { Entry&lt;Long, String&gt; entry = it.next(); Long brokerId = entry.getKey(); String brokerAddr = entry.getValue(); if (brokerAddr.equals(brokerAddrFound)) { brokerNameFound = brokerData.getBrokerName(); //删除 it.remove(); log.info(\"remove brokerAddr[{}, {}] from brokerAddrTable, because channel destroyed\", brokerId, brokerAddr); break; } } if (brokerData.getBrokerAddrs().isEmpty()) { removeBrokerName = true; itBrokerAddrTable.remove(); log.info(\"remove brokerName[{}] from brokerAddrTable, because channel destroyed\", brokerData.getBrokerName()); } } if (brokerNameFound != null &amp;&amp; removeBrokerName) { Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator(); while (it.hasNext()) { Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next(); String clusterName = entry.getKey(); Set&lt;String&gt; brokerNames = entry.getValue(); boolean removed = brokerNames.remove(brokerNameFound); if (removed) { log.info(\"remove brokerName[{}], clusterName[{}] from clusterAddrTable, because channel destroyed\", brokerNameFound, clusterName); if (brokerNames.isEmpty()) { log.info(\"remove the clusterName[{}] from clusterAddrTable, because channel destroyed and no broker in this cluster\", clusterName); it.remove(); } break; } } } //在topick路由表进行更新 if (removeBrokerName) { Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable = this.topicQueueTable.entrySet().iterator(); while (itTopicQueueTable.hasNext()) { Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next(); String topic = entry.getKey(); List&lt;QueueData&gt; queueDataList = entry.getValue(); Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator(); while (itQueueData.hasNext()) { QueueData queueData = itQueueData.next(); if (queueData.getBrokerName().equals(brokerNameFound)) { itQueueData.remove(); log.info(\"remove topic[{} {}], from topicQueueTable, because channel destroyed\", topic, queueData); } } if (queueDataList.isEmpty()) { itTopicQueueTable.remove(); log.info(\"remove topic[{}] all queue, from topicQueueTable, because channel destroyed\", topic); } } } } finally { //最后进行解锁操作 this.lock.writeLock().unlock(); } } catch (Exception e) { log.error(\"onChannelDestroy Exception\", e); } } } 可以看到每当有broker下线时，整个路由信息都会通过加锁的方式进行实时更新。 在初始化了NamesrvController实例以后，下面就是调用它的初始化方法initialize()。 NamesrvController.java1234567891011121314 //读取KV配置 this.kvConfigManager.load(); //生成netty远程服务 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); //线程池初始化 this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(\"RemotingExecutorThread_\"));//注册处理类this.registerProcessor();//跳过定时线程初始化和ssl... 最后调用start()方法，其实就是netty的启动。 参考《rocketmq技术内幕》","link":"/2019/05/07/rocketmq1/"}],"tags":[{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"spring security","slug":"spring-security","link":"/tags/spring-security/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"rocketmq","slug":"rocketmq","link":"/tags/rocketmq/"}],"categories":[]}
{"pages":[{"title":"分类","text":"","link":"/categories/index.html"}],"posts":[{"title":"monotonous","text":"Spring Event 关于ContextStartedEvent 使用 问题 在spring boot 中定义event listener 实现ContextStartedEventListener 监听上下文启动实现.发现项目启动后项目并不会打印出我们所需要的日志 ContextStartedEventListener.java12345678910111213@Componentpublic class ContextStartedEventListener implements ApplicationListener&lt;ContextStartedEvent&gt; { private static final Logger log = LoggerFactory.getLogger(ContextStartedEventListener.class); @Override public void onApplicationEvent(ContextStartedEvent event) { log.info(\"ContextStartedEventListener : 项目启动\"); }} 解析 打开spring 源码发现在AbstractApplicationContext#start() 方法中调用了此方法。 ContextStoppedEvent同理也是stop方法。 AbstractApplicationContext.java12345678910111213@Overridepublic void start() { getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));}@Overridepublic void stop() { getLifecycleProcessor().stop(); publishEvent(new ContextStoppedEvent(this));} 定位到调用该方法的地方为DefaultLifecycleProcessor#start(). 很明显是在生命周期的处理器中调用。再次定位调用这个start方法的来源。 AbstractApplicationContext.java12345678 @Overridepublic void start() { getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));} 结论我们一般启动spring boot 是使用AbstractApplicationContext#refresh方法而不是start()方法，所以这里只能使用abstractApplicationContext 的start方法启动上下文是才会产生这个事件。 后记在DefaultLifecycleProcessor中使用spring boot 启动使用的是 DefaultLifecycleProcessor.java12345@Override public void onRefresh() { startBeans(true); this.running = true; } 他和刚刚的abstrctApplicationContext调用地start方法只有一个参数autoStartupOnly的区别。这个参数为false时即我们abstrctApplicationContext.start时可以在我们的lifecycle bean 上使用注解@Phase 定义生命周期的阶段，从而自定义lifecycle bean 的start顺序。 这个注解还和timeoutPerShutdownPhase这个产数有关，timeoutPerShutdownPhase定义了lifecycle bean stop的超时时间DefaultLifecycleProcessor.java1234567891011121314151617181920212223242526public void stop() { if (this.members.isEmpty()) { return; } this.members.sort(Collections.reverseOrder()); CountDownLatch latch = new CountDownLatch(this.smartMemberCount); Set&lt;String&gt; countDownBeanNames = Collections.synchronizedSet(new LinkedHashSet&lt;&gt;()); Set&lt;String&gt; lifecycleBeanNames = new HashSet&lt;&gt;(this.lifecycleBeans.keySet()); for (LifecycleGroupMember member : this.members) { if (lifecycleBeanNames.contains(member.name)) { doStop(this.lifecycleBeans, member.name, latch, countDownBeanNames); } else if (member.bean instanceof SmartLifecycle) { // Already removed: must have been a dependent bean from another phase latch.countDown(); } } try { latch.await(this.timeout, TimeUnit.MILLISECONDS); } catch (InterruptedException ex) { Thread.currentThread().interrupt(); } } 」","link":"/2021/05/14/ContextStartedEvent/"},{"title":"关于spring boot在请求参数中使用枚举(enums)的几种方式 (1)","text":"在日常开发中，我们都会在请求中使用某些枚举类型，这样不仅能够防止恶意客户端输入一些错误值，提高程序的健壮性，还可以提高代码的可读性和可维护性。当时当我们在request 参数中添加枚举后，spring boot并不会帮助我们自动解析成枚举，这就需要我们能够自己配置了。 1.直接使用字符串先定义一个接收输入的枚举类 RequestEnum.java1234567891011121314151617181920212223242526public enum RequestEnum { /** * A */ A(\"A\"), /** * B */ B(\"B\"); RequestEnum(String code) { this.code = code; } private String code; public String getCode() { return code; } public void setCode(String code) { this.code = code; }} 接着定义一个接收GET请求的接口 EnumController.java12345@GetMapping public ResponseEntity&lt;?&gt; getEnumRequest(@RequestParam RequestEnum A) { return ResponseEntity.ok(A.getCode()); } 这个时候我们启动项目，在浏览器输入http://localhost:8080/**?A=A 这个时候能够看到浏览器显示一个字母A 说明spring boot 能够把我们的字符串成功转换成枚举RequestEnum。 2.使用Integer或者其他类型我们再定义一个枚举IntegerRequestEnum.java1234567891011121314151617181920212223242526public enum IntegerRequestEnum { /** * A */ A(1), /** * B */ B(2); IntegerRequestEnum(Integer code) { this.code = code; } private Integer code; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; }} 接着编写接收这个枚举的接口 EnumController.java12345@GetMapping(\"int\") public ResponseEntity&lt;?&gt; getIntegerEnumRequest(@RequestParam IntegerRequestEnum A) { return ResponseEntity.ok(A.getCode()); } 这个时候我们在浏览器输入http://localhost:8080/**/int?A=2 发现浏览器返回浏览错误信息 There was an unexpected error (type=Bad Request, status=400). 3.解析为什么String类型可以直接解析成枚举而字符串不能呢？我们看下他是怎么解析的。InvocableHandlerMethod.java12345678910111213141516171819202122protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { if (ObjectUtils.isEmpty(getMethodParameters())) { return EMPTY_ARGS; } MethodParameter[] parameters = getMethodParameters(); Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) { MethodParameter parameter = parameters[i]; // 省略部分代码 try { args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); } catch (Exception ex) { //错误处理 } } return args; } 在InvocableHandlerMethod.java 这个类里spring 通过反射帮我们获取了方法接收的参数的类型，然后通过resolvers去查找处理(里面使用map保存,增加速度).最终调用了RequestParamMethodArgumentResolver的父类AbstractNamedValueMethodArgumentResolver来处理。 AbstractNamedValueMethodArgumentResolver.java12345678910111213141516171819202122232425public final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception { // 获取值 Object arg = resolveName(resolvedName.toString(), nestedParameter, webRequest); // @RequestParam 的值处理 if (arg == null) { if (namedValueInfo.defaultValue != null) { arg = resolveStringValue(namedValueInfo.defaultValue); } // 在这里optional是可以为空的 else if (namedValueInfo.required &amp;&amp; !nestedParameter.isOptional()) { handleMissingValue(namedValueInfo.name, nestedParameter, webRequest); } arg = handleNullValue(namedValueInfo.name, arg, nestedParameter.getNestedParameterType()); } else if (\"\".equals(arg) &amp;&amp; namedValueInfo.defaultValue != null) { arg = resolveStringValue(namedValueInfo.defaultValue); } // 在这里处理成我们想要的枚举类型 arg = binder.convertIfNecessary(arg, parameter.getParameterType(), parameter); } 在binder.convertIfNecessary调用方法中我们最终调用了TypeConverterDelegate这个代理类的convertIfNecessary这个方法.这里面最终执行了如下代码TypeConverterDelegate.java12345678910if (conversionService.canConvert(sourceTypeDesc, typeDescriptor)) { try { return (T) conversionService.convert(newValue, sourceTypeDesc, typeDescriptor); } catch (ConversionFailedException ex) { // fallback to default conversion logic below conversionAttemptEx = ex; } } 在这里最终会产生异常.这里面会调用String-&gt;Enum 这个converter,它是用了enum的构造方法进行转化.但是我们的IntegerRequestEnum的构造方法是Integer.另外我们通过debug还能看到conversionService的converters里一共缓存了124个converter. 所以如果我们需要解析我们的enum就需要在这个conterters里增加我们的自定义的converter.WebConfig.java123456789@Configurationpublic class WebConfig implements WebMvcConfigurer { @Override public void addFormatters(FormatterRegistry registry) { registry.addConverter(String.class, IntegerRequestEnum.class, new StringToIntegerEnumConverter()); }} 增加配置当我们再次访问http://localhost:8080/**/int?A=2之后页面就能正常返回.","link":"/2021/07/20/SpringRequestEnum1/"},{"title":"关于spring boot在请求参数中使用枚举(enums)的几种方式(2)","text":"在日常开发中，我们都会在请求中使用某些枚举类型，这样不仅能够防止恶意客户端输入一些错误值，提高程序的健壮性，还可以提高代码的可读性和可维护性。当时当我们在request 参数中添加枚举后，spring boot并不会帮助我们自动解析成枚举，这就需要我们能够自己配置了。下面介绍几种日常开发中会用的方式。 3.使用@JsonCreator一把项目中,我们使用都是POST方法使用body来接收对象,在对象中我们定义了枚举参数,但是当我们传入json字符串反序列化时，项目会出现错误400.JSON parse error: Cannot deserialize value of type. 那这个错误是怎么产生的呢？我们通过debug发现在RequestMappingHandlerAdapter.java这个类的invokeHandlerMethod方法中将请求转换为调用我们写的接口的.而这个方法最终会调用InvocableHandlerMethod.java的getMethodArgumentValues来获取其中的参数.那如何来获取呢，便是通过里面的resolver集合.当我们使用@RequestBody来接收请求参数是,系统对应的选择RequestResponseBodyMethodProcessor来处理.前面我们的GET请求是使用RequestParamMethodArgumentResolver来处理的.那RequestResponseBodyMethodProcessor是怎么处理的,它也和RequestParamMethodArgumentResolver一样是使用converter来处理,但是使用的是HttpMessageConverter,因为他是读取消息体来获取参数的. AbstractMessageConverterMethodArgumentResolver.java12345678910111213141516171819for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) { Class&lt;HttpMessageConverter&lt;?&gt;&gt; converterType = (Class&lt;HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(); GenericHttpMessageConverter&lt;?&gt; genericConverter = (converter instanceof GenericHttpMessageConverter ? (GenericHttpMessageConverter&lt;?&gt;) converter : null); if (genericConverter != null ? genericConverter.canRead(targetType, contextClass, contentType) : (targetClass != null &amp;&amp; converter.canRead(targetClass, contentType))) { if (message.hasBody()) { HttpInputMessage msgToUse = getAdvice().beforeBodyRead(message, parameter, targetType, converterType); body = (genericConverter != null ? genericConverter.read(targetType, contextClass, msgToUse) : ((HttpMessageConverter&lt;T&gt;) converter).read(targetClass, msgToUse)); body = getAdvice().afterBodyRead(body, msgToUse, parameter, targetType, converterType); } else { body = getAdvice().handleEmptyBody(null, message, parameter, targetType, converterType); } break; } } 这里我们看到程序使用了一个for循环来尝试过去处理,而我们输入的是json字符串那么最终采用的便是我们一直用的MappingJackson2HttpMessageConverter.这个converter在反序列化成枚举是便会产生异常. 那解决方法便是尝试让我们的枚举类支持反序列化方式和增加我们自己定义的converter.这里方便起见我们可以直接用@JsonCreater来让我们的枚举支持反序列化. 首先在我们的项目的IntegerRequestEnum这个枚举类中增加静态方法 IntegerRequestEnum.java123456789@JsonCreatorpublic static IntegerRequestEnum decode(Integer source) { for (IntegerRequestEnum e : IntegerRequestEnum.values()) { if (e.getCode().equals(source)) { return e; } } return A; } 请求类对象:EnumRequest.java123456789101112public class EnumRequest {private IntegerRequestEnum ir; public IntegerRequestEnum getIr() { return ir; } public void setIr(IntegerRequestEnum ir) { this.ir = ir; }} 接着定义我们的接口EnumController.java123456@PostMapping(\"/post\") public ResponseEntity&lt;?&gt; postEnumRequest(@RequestBody EnumRequest A) { return ResponseEntity.ok(A.getIr().getCode()); } 使用POSTMAN访问成功返回我们需要的值. 4.使用JsonDeserializer(不推荐)最简单的方法但是枚举类一多配置起来比较复杂 定义我们的DeserializerIntegerEnumDeserializer.java12345678public static class IntegerEnumDeserializer extends JsonDeserializer&lt;IntegerRequestEnum&gt; { @Override public IntegerRequestEnum deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException { return IntegerRequestEnum.decode(jsonParser.getIntValue()); } } 然后在我们Request对象里的枚举属性上使用注解@JsonDeserialize(using = IntegerEnumDeserializer.class) 最后阿里在开发手册中不推荐返回值使用枚举,认为枚举在可扩展性上存在不足.","link":"/2021/07/21/SpringRequestEnum2/"},{"title":"docker exec 是怎么做到进入容器里的","text":"转自极客时间深入剖析k8s 1.原理Linux Namespace 创建的隔离空间虽然看不见摸不着，但一个进程的 Namespace 信息在宿主机上是确确实实存在的，并且是以一个文件的方式存在。我们可以通过docker inspect 命令获取到正在运行的 Docker 容器的进程号（PID）。123$ docker inspect --format '{{ .State.Pid }}' ${container id}$ ls -l /proc/${Pid}/ns 可以看到，一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。这也就意味着：一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的，这正是 docker exec 的实现原理。而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。1234567891011121314151617181920#define _GNU_SOURCE#include &lt;fcntl.h&gt;#include &lt;sched.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#define errExit(msg) do { perror(msg); exit(EXIT_FAILURE);} while (0)int main(int argc, char *argv[]) { int fd; fd = open(argv[1], O_RDONLY); if (setns(fd, 0) == -1) { errExit(\"setns\"); } execvp(argv[2], &amp;argv[2]); errExit(\"execvp\");} 这段代码功能非常简单：它一共接收两个参数，第一个参数是 argv[1]，即当前进程要加入的 Namespace 文件的路径，比如 /proc/[进程号]/ns/net；而第二个参数，则是你要在这个 Namespace 里运行的进程，比如 /bin/bash。这段代码的核心操作，则是通过 open() 系统调用打开了指定的 Namespace 文件，并把这个文件的描述符 fd 交给 setns() 使用。在 setns() 执行后，当前进程就加入了这个文件对应的 Linux Namespace 当中了。 同时，一旦一个进程加入到了另一个 Namespace 当中，在宿主机的 Namespace 文件上，也会有所体现。你可以用 ps 指令找到这个 set_ns 程序执行的 /bin/bash 进程。查看一下这个 程序对应的进程的 Namespace。2个进程指向的Network Namespace 文件完全一样。123$ ps aux | grep /bin/bash$ ls -l /proc/[进程1]/ns/net$ ls -l /proc/[进程2]/ns/net 我们可以在dockers 启动命令行中增加参数–net container:XXX来加入到另外一个容器的Network Namespace 中。 2.获取root 权限在公司执行了set_ns脚本后，竟然发现原有的用户变成了root。执行id命令后12$ iduid=0(root) gid=0(root) 组=0(root)","link":"/2021/08/10/docker-exec/"},{"title":"Dockerfile ENTRYPOINT和CMD","text":"Dockerfile中ENTRYPOINT和CMD ENTRYPOINT定义容器启动时被调用的可执行程序 CMD指定传递给ENTRYPOINT的参数 ENTRYPOINT 的2种形式","link":"/2022/04/27/docker_cmd/"},{"title":"fastdfs部署及应用","text":"简介FastDFS是一个开源的轻量级分布式文件系统,为互联网应用量身定做,简单、灵活、高效,采用C语言开发,由阿里巴巴开发并开源.FastDFS对文件进行管理,功能包括：文件存储、文件同步、文件访问(文件上传、文件下载、文件删除)等,解决了大容量文件存储的问题,特别适合以文件为载体的在线服务,如相册网站、文档网站、图片网站、视频网站等等.FastDFS充分考虑了冗余备份、线性扩容等机制,并注重高可用、高性能等指标,使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务. 整体架构FastDFS文件系统由两大部分构成,一个是客户端,一个是服务端.客户端通常就是我们的程序,我们可以使用第三方的扩展包去连接fastdfs. 跟踪器(tracker)主要做调度工作,在内存中记录集群中存储节点storage的状态信息,是前端Client和后端存储节点storage的枢纽.因为相关信息全部在内存中,Tracker server的性能非常高,一个较大的集群(比如上百个group)中有3台就足够了.每个 storage 在启动后会连接 Tracker，告知自己所属 group 等信息，并保持周期性心跳。storage以group为单位,每个group里可以有多个storage单位. 存储节点(storage)用于存储文件,包括文件和文件属性(meta data)都保存到存储服务器磁盘上,完成文件管理的所有功能:文件存储、文件同步和提供文件访问等. 1.下载镜像执行命令docker search fastdfs 1234567NAME DESCRIPTION STARS OFFICIAL AUTOMATEDseason/fastdfs FastDFS 77ygqygq2/fastdfs-nginx 整合了nginx的fastdfs 27 [OK]luhuiguo/fastdfs FastDFS is an open source high performance d… 25 [OK]morunchang/fastdfs A FastDFS image 20delron/fastdfs 13qbanxiaoli/fastdfs FastDFS+FastDHT(单机+集群版) 12 [OK] 这里根据star数选取最高的 season/fastdfs,打开docker hub搜索这个镜像https://hub.docker.com/r/season/fastdfs里面有具体使用这个镜像的方法教程,这里点击tag页选取最新的版本1.2.使用docker pull season/fastdfs:1.2等待docker 帮我们自动下载好镜像. 启动tracker和storage服务 首先创建对应的文件夹1mkdir -p /home/fastdfs 启动tracker 12345docker run -id --name tracker \\-p 22122:22122 \\--restart=always --net host \\-v /home/ucmed/fastdfs/tracker/data:/fastdfs/tracker/data \\season/fastdfs:1.2 tracker 启动storage服务 12345docker run -id --name storage \\--restart=always --net host \\-v /home/fastdfs/data/storage:/fastdfs/store_path \\-e TRACKER_SERVER=&quot;192.168.3.134:22122&quot; \\season/fastdfs:1.2 storage 这里笔者曾使用TRACKER_SERVER=”127.0.0.1” 但是启动服务使用命令docker logs发现程序并为成功启动.提示TRACKER_SERVER不能设置成127.0.0.1. 搭建完2个容器后进入tracker 进行测试1234docker exec -it tracker bashcd /etc/fdfs/lscat client.conf 输出的 client.conf 都是默认配置，我们可以找到其中的 track_server 将默认的地址改成我们设置的storage地址执行命令123docker cp trakcer:/etc/fdfs/client.conf /home/fastdfs/vim client.confdocker cp /home/fastdfs/client.conf tracker:/etc/fdfs 修改其中的track_server地址 执行命令12docker exec -it tracker bashfdfs_monitor /etc/fdfs/client.conf 控制台会输出DEBUG信息1DEBUG - base_path=/fastdfs/client, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0 表示storage已经成功的连上了我们的tracker.之后尝试上传文件12#fdfs_upload_file /etc/fdfs/client.conf **.txtgroup1/M00/00/00/wKgDhmECa5GAGpHOAAAABncc3SA469.txt 这样fastdfs就搭建完成了 3.nginx 服务如果想要访问我们上传的文件 就需要启动nginx modual.拷贝出nginx配置文件 修改其中的location节点 123456789docker cp storage:/etc/nginx/conf/nginx.conf /home/fastdfs/nginx/docker run -id --name fastdfs_nginx \\--restart=always \\-v /home/fastdfs/data/storage:/fastdfs/store_path \\-v /home/fastdfs/nginx.conf:/etc/nginx/conf/nginx.conf \\-p 80:80 \\-e TRACKER_SERVER=192.168.3.134:22122 \\season/fastdfs:1.2 nginx 这时候打开浏览器访问http://192.168.3.134/group1/M00/00/00/wKgDhmECa5GAGpHOAAAABncc3SA469.txt出现刚刚上传的文件信息. 4.spring boo 集成增加maven 依赖pom.xml12345&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;version&gt;1.27.2&lt;/version&gt; &lt;/dependency&gt; 在Maven当中配置依赖以后，SpringBoot项目将会自动导入FastDFS依赖添加config ComponetImport.java12345678910111213/** * 导入FastDFS-Client组件 * * @author tobato * */@Configuration@Import(FdfsClientConfig.class)// 解决jmx重复注册bean的问题@EnableMBeanExport(registration = RegistrationPolicy.IGNORE_EXISTING)public class ComponetImport { // 导入依赖组件} 在application.yml当中配置Fdfs相关参数 application.yml123456789101112fdfs: connect-timeout: 500 so-timeout: 5000 thumb-image: width: 200 height: 200 tracker-list: - 192.168.3.134:22122 pool: max-total: 3 max-total-per-key: 5 max-idle-per-key: 3 编写上传接口 FastDfsController.java123456789101112131415161718@RequestMapping(\"/dfs\")@RestControllerpublic class FastDfsController {private final FastFileStorageClient fastFileStorageClient; public FastDfsController(FastFileStorageClient fastFileStorageClient) { this.fastFileStorageClient = fastFileStorageClient; } @PostMapping(value = \"/upload\",consumes = {MediaType.MULTIPART_FORM_DATA_VALUE, MediaType.IMAGE_PNG_VALUE}) public ResponseEntity&lt;?&gt; upload(MultipartFile multipartFile) throws IOException { String extension = FilenameUtils.getExtension(multipartFile.getOriginalFilename()); FastFile fastFile = new FastFile(multipartFile.getInputStream(), multipartFile.getSize(), extension, new HashSet&lt;&gt;()); StorePath storePath = fastFileStorageClient.uploadFile(fastFile); return ResponseEntity.ok(storePath.getFullPath()); }} 调用我们的接口后便会返回对应的路径.","link":"/2021/07/29/fastdfs/"},{"title":"pod绑定hostPort和nodePort服务区别","text":"pod绑定hostPort和nodePort服务区别pod通过配置spec.containers.ports属性来将pod的containerPort和pod所在的宿主节点hostPort节点绑定. 对于使用了hostPort的节点，到达宿主节点的端口的连接会被直接转发到pod对应的端口上；然而对于绑定了nodePort服务的应用，k8s会随机转发到不同节点的pod。 另外一个区别，对于使用hostPort的pod，仅有运行了这类pod的节点会绑定对应的端口，而nodePort服务会在所有节点上绑定端口，即使这个节点上没运行对应的pod。 同时如果pod绑定了宿主机上的一个特定端口，每个节点就只能调度一个这样的pod实例，因为2个进程不能绑定同一个端口，如果3个节点上要调度4个这样的pod，那么会有1个pod永远处于pending状态。 hostPort最初使用于DeamonSet部署的系统服务，也用来保障pod的2个副本不会调度到同一节点上。","link":"/2022/07/21/hostPort-nodePort/"},{"title":"icarus-bug","text":"##记一次hexo切换主题icarus排版混乱的bug ######起因 第一次使用hexo搭建blog,看到icarus主题漂亮就入了坑，本地运行完美。仿照国内教程各种详细的配置。 http://blog.kimzing.com/ 准备remote上传 1sudo hexo d -g 一切ok,打开网站却发现左边的介绍去了中间，样式全无。按F12查看控制台发现并没有脚本或者css报错信息，只能google. 搜索内容如下 1.查看css文件完整性 打开F12对比发现完全一下 2.修改根目录下的url 设置完发现无用 ######结果 在下面helloworld中发现了类似图片404的图片，于是就想着先删除它，在本地rm helloworld.md后 12sudo hexo gsudo hexo d hellowold 没删掉 排版好了。。。","link":"/2019/04/18/icarus-bug/"},{"title":"k8s deployment 不更新的例子","text":"K8S deployment 不更新案例patch 命令使用patch命令更改deployment的自有属性，并不会导致pod的任何更新，因为pod模板并没有被修改，更改其他deployment的属性，如所需副本数或者部署策略也不会触发滚动升级，现有运行中的pod也不会受影响。 1kubectl pathch deployment deployment_name -p &apos;{&quot;spec&quot;:{&quot;minReadySeconds:10&quot;}}&apos; config/secret如果deployment中的pod模板引用了一个configmap(或secret)，那么修改configmap资源本身并不会触发升级操作，如果真的需要修改程序的配置并触发更新，可以创建一个新的configmap并修改pod模板引用新的configmap。 其他ReplicaSet在deployment更新后仍会保留旧的用于回滚，而replicationController不会。","link":"/2022/07/17/k8s-deployment-update/"},{"title":"k8s_svc笔记","text":"K8S service 对象笔记(1)1.loadbalance 作用loadbalance 对象主要作用是将pod服务暴露出来，并提供负载均衡的作用。loadbalance不像NodePort那样在每个集群的节点上打开一个端口那样访问，他拥有自己独一无二的可公开访问的IP地址，在使用kubectl get svc 的EXTERNAL-IP那一列可以看到，可以通过这些ip访问服务。 如果k8s在不支持loadbalance环境中运行，则不会调配负责平衡器，但该服务仍将表现得像一个NodePort服务，loadbalance是NodePort服务的扩展。 浏览器会话亲和性由于浏览器使用keep-alive连接，当浏览器首次与服务连接时，第一次会随机选择一个集群，然后会将属于该连接的所有请求都会发往第一次建立连接的集群，即使会话亲和性设置成None，用户也会使用相同的pod直到连接关闭。 不必要的网络跳数当外部浏览器通过端口连接服务时，随机选择的pod并不一定在接收连接的同一节点上，这就可能需要额外的网路跳。同时这会可能导致对数据包执行源网络地址转换（SNAP）, 数据包的源ip就会发生变化，会影响后端服务获取客户端的ip地址。 这时候可以在服务的spec中设置externalTrafficPolicy为Local来避免这种情况。 12spec: externalTrafficPolicy: Local 如果服务使用了该设置，并且通过服务的节点端口打开外部连接时，服务代理会选择本地运行的pod，如果没有本地pod，就将连接挂起(并不会像不使用那样转发到全局随机pod),所以需要确保负载均衡到一个有pod服务的节点。 同时该设置会导致如果节点上pod的数量不相等，使用Local外部流量策略会导致pod的负载分布不均衡。 ingress工作原理客户端先对要访问的域名做DNS查找，DNS服务器返回ingress控制器的ip地址（可以通过kubectl get ingresses 命令的ADDRESS一列中找到对应的ip）。然后客户端向控制器发送请求并在Host头中指定要访问的域名，控制器从该头部中确定访问具体的哪个服务，通过与该服务相关联的Endpoint对象查看ip，然后向其中的一个pod转发。 参考 《Kubernetes in action》","link":"/2022/04/26/k8s-svc1/"},{"title":"k8s pod 属性","text":"k8s pod 属性健康检查指针 livenessProbe 探活，当检查失败时，意味着当前应用挂了，kubelet会kill进程并按照restartPolicy来决定是否重启pod。 readinessProbe 就绪状态检测，当检查失败时，意味着容器进程正在运行，但因为某些原因不能提供服务，pod状态被标记为notReady。并不会去kill。 startupProbe 在初始化阶段之前（ready之前）进行的健康检查，通常用来避免过于频繁的检测影响应用启动。 探测方法 ExecAction:在容器内部运行指定命令，当返回码为0时，结果为成功 TCPSocketAction:用kubelet发起，通过TCP协议检查ip和端口，当ip和端口可达时，表示成功。 HTTPGetAction:用kubelet发起，发送http get请求，返回状态码200-400之间为成功。 startupProbe和initialDelaySecond的区别 initialDelaySecond只能是一个固定的数字，不能够根据具体应用的状态来判断pod是否启动成功。startupProbe可以设置initialDelaySecond，并且成功后就不再执行对应的探活操作。 qosclass和priority的区别 qosclass发生在资源不够用的情况下，而priority发生在pod调度阶段。 postStart12345spec: containers: lifecycle: postStart: exec: 无法保证postStart脚本和容器的Entrypoint哪个先执行postStart 结束之前，容器不会被标记为running状态。 preStop12spec: terminationGracePeriodSeconds: 30 terminationGracePeriodSeconds 当preStop和kill -SIGTERM多少秒之后才执行kill -SIGKILL。 只用当pod被终止时，k8s才会执行preStop脚本，这意味着当pod容器完成或退出时，preStop脚本不会被执行。 sh命令不能相应SIGTERM信号。","link":"/2022/05/17/k8s_pod/"},{"title":"k8s_rest_api","text":"k8s rest apiDownwardAPI K8S可以通过DownwardAPI来获取pod自身的ip，命名空间，名称等。 第一种，通过环境变量的方式。 123456spec: env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name pod创建完成后可以通过kubectl exec downward env 查看。 第二种，通过DownwardAPI卷的方式。 123456789101112spec: containers: volumeMounts: - name: downward mountPath: /etc/downward volumes: - name: downward downwardAPI: items: - path: &quot;POD_NAME&quot; fieldRef: fieldPath: metadata.name 在pod内部来连接k8s api 服务器curl https://kubenetes 会返回ssl证书错误，可以使用-k选项绕过，但是这样不安全。我们可以使用在创建pod时自动创建的secret。 在/var/run/secrets/kubernetes.io/serviceaccount目录下会生成对应的secret文件，我们可以使用--cacerthttps://kubenetes ```命令 这时我们会看到返回Unauthorized.我们可以设置CURL_CA_BUNDLE环境变量来简化操作12```export CURL_CA_BUNDLE=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt。 要解决Unauthorized，我们需要获得授权。12#TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)#curl -H &quot;Authorization: Bearer $TOKEN&quot; https://kubenetes","link":"/2022/07/10/k8s-rest-api/"},{"title":"mysql8","text":"mysql 8 新特性mysql分库分表并不是一定从性能的角度上需求，大部分场景是为了更好的管理数据 数据量大时需要对数据进行新加字段进行加以归类标记，DDL会锁表导致长时间堵塞。(mysql 8 特性会大幅度缩短这个时间，同时mysql 8增加了备份锁，减少备份的时间) 当一张表或者一个库出现问题时不会导致整个应用不能访问db. 灰度？数据库性能。 WHERE 语句内使用函数走索引select * from x where YEAR(date) = 2021 降序索引 mysql索引以前一直都是顺序，现在可以按降序存储。 index idx_c1_c2(c1,c2 desc)在索引反向扫描是 explain 语句extra中会显示Backward index scan GROUP BY 语句不在隐式排序现在select group by 语句不会按照group by 字段进行隐式排序mysql 5x 中explain 语句的extra 中有Using filesort 在高并发的情况下性能提升在高并发的情况下，只读和更新操作性能提升 默认字符集为utf8mb4修改默认字符集，同时查询性能增加 增加SKIP LOCKED 和NOWAITselect from x where id = 1 for update skip lockedselect from x where id = 1 for update skip nowait 前者查询加锁的记录被其他线程持有锁时会直接返回空。后者查询加锁的记录被其他线程持有锁时会直接报错。在高并发下比如抢红包等场景下使用。 文档数据库mysql 支持nosql的crud.同时提供了JSON函数 新增统计函数和GIS窗口函数。(不常用)GIS 地理信息(不常用) DDL 原子性数据字典集中存储，增强crash safe能力。 MGR 增强MGR 集群的健壮和稳定性加强。 自增主键id存储 在删除一条数据后又新增一条数据在mysql8之前,自增主键的最大值存储在内存中。mysql8将自增id在事务结束checkpoint时放到了redolog中。所以mysql8之前id会持续增大而8会使用之前的。","link":"/2021/07/15/mysql8/"},{"title":"monotonous","text":"单调栈结构问题给定一个不含有重复值的数组arr,找到每一个i位置左边和右边离i位置最近且值比arr[i]小的位置，返回所有位置相应的信息。时间复杂度 O（N）。 举例arr = [3,4,1,5,6,2,7] 返回数组 [[-1,2],[0,2],[-1,-1],[2,5],[3,5],[2,-1],[5,-1]] -1表示不存在。 解答准备一个栈 stack, 栈中存放数组中的元素，初始化stack为空。如果要求找到每一个i位置左边和右边离i位置最近且值比arr[i]小的位置，就么就需要然stack从栈顶到栈底的位置所代表的元素值必须是严格递减的，反之亦然。这里是递减。 初始化arr = [3,4,1,5,6,2,7],stack = {}. 遍历到arr[0] == 3, i == 0,发现stack为空，将 位置0 入栈 ,stack变为 {0(3)}. 遍历到arr[1] == 4, 发现将 1（4）放入stack不会破坏stack从栈顶到栈底严格递减，直接放入. stack变为 {1(4),0(3)} 遍历到arr[2] == 1, i == 2 发现将 2（1）放入stack会破坏严格递减的规则，所以从stack的栈顶开始弹出元素。如果x位置被弹出，在栈中位于x位置下面的位置就是左边离x位置最近且比arr[x]小的位置，i 就是x位置右边离x位置最近且比arr[x]小的位置。所以ans[1] = [0, 2].弹出x(1)后发现放入位置2（1）还是会破坏严格递减的规则，所以弹出0（3），因为stack在0（3）下面没有元素了，说明在位置0（3）左边没有存在比它还小的元素，所以ans[0] = [-1, 2].此时stack 为空，将2（1）压入stack. 遍历到arr[3] == 5 ,发现arr[3] &gt; arr[2], 直接放入3（5）， stack依次为{3(5), 2(1)} 遍历到arr[4] == 6 ,同上放入， stack依次为{4(6), 3(5), 2(1)} 遍历到arr[5] == 2, 因为放入会破坏单调递减， 依次弹出4(6), 3(5)， 位置4下面是3，所以ans[4] = {3,5},位置3下面是位置2， 所以ans[3] = {2,5}. 最后放入5(2)， stack依次为{5(2), 2(1)} 遍历到 arr[6] == 7, 直接放入stack ，stack依次为{6(7), 5(2), 2(1)} 遍历阶段结束后，清算栈中剩下的位置。因为是清算过程中，所以数组中不存在在右边比它们小的元素，所以ans[x] = {?, -1} 弹出位置6， 栈中它下面的位置是5(2), 所以ans[6] = {5, -1}弹出位置5， 栈中它下面的位置是2(1), 所以ans[6] = {2, -1}最后只剩下2(1)，因为栈中已经没有元素了，所以ans[2] = {-1,-1}至此全部完成，整个流程中，每个位置都进栈一次，出栈一次，所以整个流程的时间复杂度为O（N） 重复问题当数组中的元素允许重复时，元素（位置）入栈时不变，如果值相同则将位置替换。 代码solution.java123456789101112131415161718192021222324public int[][] getNearLessNoRepeat(int[] arr){ int[][] res = new int[arr.length][2]; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) { while (!stack.empty() &amp;&amp; arr[stack.peek()] &gt; arr[i]){ int a = stack.pop(); int left = stack.isEmpty() ? -1 : stack.peek(); res[a][0] = left; res[a][1] = i; } stack.push(i); } //遍历完 while (!stack.isEmpty()){ int a = stack.pop(); int left = stack.isEmpty() ? -1 : stack.peek(); res[a][0] = left; res[a][1] = -1; } return res; } 来源左程云 《程序员算法面试指南》","link":"/2019/05/06/monotonous/"},{"title":"pod删除时的动作","text":"Pod删除时的动作当API服务器接受到删除pod的请求后，它首先会修改etcd中的状态并且把删除事件通知给观察者，其中2个就是kubelet和端点控制器，2个事件是并行的。 kubelet。kubelet接收到pod终止的通知时,API服务器会给pod设置一个deletionTimestamp，拥有deletionTimestamp的pod就开始停止了。当kubelet发现这个deletionTimestamp，它会按照pod设置的Termination Grace Period时间段内实现优雅停止。这个值可以用过spec.terminationGracePeriodPeriods来设置。 我们可以通过命令行设置--grace-period=0 --force来强制API服务器删除pod，但是当用这个命令删除StatefulSet的pod的时候,控制器不会等待被删的pod中的容器完成关闭就会创建一个新的pod，这样就会导致同一时间可能有2个相同的pod在同一时间运行。 kubelet会按顺序执行以下事件 1.执行pre-stop的勾子命令，等待它执行完毕 2.向容器主进程发送sigterm信号（这里要注意如果容器是通过一个shell进程执行，然后在shell进程内部执行应用程序，这个信号会被shell吞掉，所以可以在Dockerfile中使用ENTRYPOINT或CMD的exec方式，即ENTRYPOINT [&quot;/java&quot;] 而不是ENTRYPOINT /java） 3.等待容器优雅关闭或者等待terminationGracePeriodPeriods时间超时 4.如果容器主进程没有优雅关闭，使用sigkill信号强制终止进程 当容器关闭后，连接到应用的客户端会 connection refuse。 端点控制器。端点控制器运行在控制面的controller manager中，当它接受到pod删除的事件的时候，它会把所有pod所在的service中移除这个pod的服务端点，它通过向API服务器发送REST请求修改endpoint API对象，API服务器会通知kube-proxy修改自己节点上的iptables规则，移除iptables规则对已连接的客户端不产生影响，这些客户端还可以通过这些连接发生请求。 因为这2个事件是同时发生，最有可能的是关闭pod的时间比修改iptables规则所消耗的时间少一点，这会导致pod已经关闭但是还是会有一些请求连接到pod上去，并导致连接拒绝错误。 我们可以延长pod关闭的时间或者pre-stop勾子让程序睡几秒钟等待iptables规则修改，但这会导致pod关闭会很慢。 关闭有状态的pod关闭有状态的pod有时候无法保证一些数据在pod关闭前同步到其他节点上去。解决办法是使用一些cronJob来周期性的处理孤立数据。 来源&lt;&lt;kubernetes in action&gt;&gt;","link":"/2022/07/26/pod-delete/"},{"title":"java 自定义限流器","text":"Java 自定义限流器 1.使用AtomicInetger cas实现Bucket.java123456789101112131415161718192021222324252627282930public class Bucket { private String name; private AtomicInteger count; public Bucket(String name) { this.name = name; count = new AtomicInteger(1); } public String getName() { return name; } public void setName(String name) { this.name = name; } public AtomicInteger getCount() { return count; } public void setCount(AtomicInteger count) { this.count = count; }} RateLimiterAop.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Aspect@Componentpublic class RateLimiterAop { private static final Logger LOGGER = LoggerFactory.getLogger(RateLimiterAop.class); private static final Map&lt;String, Bucket&gt; BUCKETS = new ConcurrentHashMap&lt;&gt;(); private final Object mux = new Object(); private static ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1); static { executorService.scheduleAtFixedRate(() -&gt; { BUCKETS.values().stream().forEach(b -&gt; { if (b.getCount().get() &gt; 0) { b.getCount().decrementAndGet(); } }); }, 0, 100, TimeUnit.MILLISECONDS); } @Around(\"execution(* com.ygdxd.ratelimiter.*.*(..))\") public Object limit(ProceedingJoinPoint joinPoint) throws Throwable { //获取访问目标方法 MethodSignature methodSignature = (MethodSignature)joinPoint.getSignature(); Method targetMethod = methodSignature.getMethod(); String apiName = targetMethod.getDeclaringClass().getName() + \".\" + targetMethod.getName(); Bucket bucket = BUCKETS.get(apiName); if (bucket == null) { synchronized (mux) { BUCKETS.putIfAbsent(apiName, new Bucket(apiName)); } } else { // 重试太多次 直接失败 也可以加锁 if (!addCount(bucket, 0)) {// throw new RuntimeException(\"超出限制次数\"); LOGGER.error(\"失败\"); } } return joinPoint.proceed(); } private boolean addCount(Bucket bucket, int i) { if (i &gt; 3) { return false; } int count = bucket.getCount().get(); if (count &lt;= 10) { if (!bucket.getCount().compareAndSet(count, count + 1)){ return addCount(bucket, i + 1); } return true; } else { return false; } }} 2.使用Semapphore实现(接口只能有几个线程，并不是每秒几个request)SemaphoreRateLimiterAop.java1234567891011121314151617181920212223242526272829303132333435363738394041@Aspect@Componentpublic class SemaphoreRateLimiterAop { private static final Logger LOGGER = LoggerFactory.getLogger(SemaphoreRateLimiterAop.class); private static final Map&lt;String, SemaphoreBucket&gt; BUCKETS = new ConcurrentHashMap&lt;&gt;(); private final Object mux = new Object(); @Around(\"execution(* com.ygdxd.ratelimiter.*.*(..))\") public Object limit(ProceedingJoinPoint joinPoint) throws Throwable { //获取访问目标方法 MethodSignature methodSignature = (MethodSignature)joinPoint.getSignature(); Method targetMethod = methodSignature.getMethod(); String apiName = targetMethod.getDeclaringClass().getName() + \".\" + targetMethod.getName(); SemaphoreBucket bucket = BUCKETS.get(apiName); if (bucket == null) { synchronized (mux) { bucket = new SemaphoreBucket(apiName); BUCKETS.putIfAbsent(apiName, bucket); } } boolean ack = false; try { ack = bucket.getCount().tryAcquire(1, TimeUnit.SECONDS); if (!ack) { throw new RuntimeException(\"限流了！\"); } return joinPoint.proceed(); } catch (Exception e) { LOGGER.error(\"error:\", e); throw new RuntimeException(\"失败！\"); }finally { if (ack) { bucket.getCount().release(); } } }} SemaphoreBucket.java12345678910111213141516171819202122232425262728public class SemaphoreBucket { private String name; private Semaphore count; public SemaphoreBucket(String name) { this.name = name; count = new Semaphore(3); } public String getName() { return name; } public void setName(String name) { this.name = name; } public Semaphore getCount() { return count; } public void setCount(Semaphore count) { this.count = count; }}","link":"/2021/08/25/ratelimiter/"},{"title":"SerializeLambda","text":"在mybatis plus 查询中想根据某个字段排序,但是字段是字符串类型,百度了下mysql提供了几种方法。 比如根据code进行排序123456789#1.ORDER BY `code` * 1 ASC#2.ORDER BY `code` + 0 ASC#1.ORDER BY CAST(`code` AS DECIMAL) ASC 然而项目中代码使用了LambdaQueryWrapper 里面指定了使用lambda来指定排序的列，并不能根据想要的特殊情况进行排序。 本来想着entity里加一个数据库不存在的字段 然后设置这个字段的名称为 code+0 但是mybatis plus 不会把@Tablefiled中exist为false的放进去 AbstractLambdaWrapper 获取不到对应的列信息COLUMN_CACHE_MAP 是根据TableInfo 创建的.在initTableFields时会过滤12345678910111213141516171819202122private synchronized static TableInfo initTableInfo(Configuration configuration, String currentNamespace, Class&lt;?&gt; clazz) { /* 没有获取到缓存信息,则初始化 */ TableInfo tableInfo = new TableInfo(clazz); tableInfo.setCurrentNamespace(currentNamespace); tableInfo.setConfiguration(configuration); GlobalConfig globalConfig = GlobalConfigUtils.getGlobalConfig(configuration); /* 初始化表名相关 */ final String[] excludeProperty = initTableName(clazz, globalConfig, tableInfo); List&lt;String&gt; excludePropertyList = excludeProperty != null &amp;&amp; excludeProperty.length &gt; 0 ? Arrays.asList(excludeProperty) : Collections.emptyList(); /* 初始化字段相关 */ initTableFields(clazz, globalConfig, tableInfo, excludePropertyList); /* 自动构建 resultMap */ tableInfo.initResultMapIfNeed(); /* 缓存 lambda */ LambdaUtils.installCache(tableInfo); return tableInfo; } 123456789public static List&lt;Field&gt; getAllFields(Class&lt;?&gt; clazz) { List&lt;Field&gt; fieldList = ReflectionKit.getFieldList(ClassUtils.getUserClass(clazz)); return fieldList.stream() .filter(field -&gt; { /* 过滤注解非表字段属性 */ TableField tableField = field.getAnnotation(TableField.class); return (tableField == null || tableField.exist()); }).collect(toList()); } 查看了下如何获取列名的源码 12345678910111213public static &lt;T&gt; SerializedLambda resolve(SFunction&lt;T, ?&gt; func) {Class&lt;?&gt; clazz = func.getClass();String name = clazz.getName();// 使用WeakReference缓存return Optional.ofNullable(FUNC_CACHE.get(name)).map(WeakReference::get).orElseGet(() -&gt; { // 这里根据lambda 获取SerializedLambda SerializedLambda lambda = SerializedLambda.resolve(func);FUNC_CACHE.put(name, new WeakReference&lt;&gt;(lambda));return lambda;});} 12345678910111213141516171819202122232425262728/** * 通过反序列化转换 lambda 表达式，该方法只能序列化 lambda 表达式，不能序列化接口实现或者正常非 lambda 写法的对象 * * @param lambda lambda对象 * @return 返回解析后的 SerializedLambda */ public static SerializedLambda resolve(SFunction&lt;?, ?&gt; lambda) { if (!lambda.getClass().isSynthetic()) { throw ExceptionUtils.mpe(\"该方法仅能传入 lambda 表达式产生的合成类\"); } // 使用字节码进行读取 try (ObjectInputStream objIn = new ObjectInputStream(new ByteArrayInputStream(SerializationUtils.serialize(lambda))) { @Override protected Class&lt;?&gt; resolveClass(ObjectStreamClass objectStreamClass) throws IOException, ClassNotFoundException { Class&lt;?&gt; clazz; try { clazz = ClassUtils.toClassConfident(objectStreamClass.getName()); } catch (Exception ex) { clazz = super.resolveClass(objectStreamClass); } return clazz == java.lang.invoke.SerializedLambda.class ? SerializedLambda.class : clazz; } }) { return (SerializedLambda) objIn.readObject(); } catch (ClassNotFoundException | IOException e) { throw ExceptionUtils.mpe(\"This is impossible to happen\", e); } } 123456789101112131415161718192021/** * 获取 SerializedLambda 对应的列信息，从 lambda 表达式中推测实体类 * &lt;p&gt; * 如果获取不到列信息，那么本次条件组装将会失败 * * @param lambda lambda 表达式 * @param onlyColumn 如果是，结果: \"name\", 如果否： \"name\" as \"name\" * @return 列 * @throws com.baomidou.mybatisplus.core.exceptions.MybatisPlusException 获取不到列信息时抛出异常 * @see SerializedLambda#getImplClass() * @see SerializedLambda#getImplMethodName() */ private String getColumn(SerializedLambda lambda, boolean onlyColumn) { // 获取类名 Class&lt;?&gt; aClass = lambda.getInstantiatedType(); // 初始化 主要是缓存一下列信息 tryInitCache(aClass); String fieldName = PropertyNamer.methodToProperty(lambda.getImplMethodName()); ColumnCache columnCache = getColumnCache(fieldName, aClass); return onlyColumn ? columnCache.getColumn() : columnCache.getColumnSelect(); } SerializedLambda这里面发现能把lambda表达式进行序列化,然后获取相关lambda的信息.","link":"/2021/09/06/serialize-lambda/"},{"title":"spring security 1 配置类加载","text":"##spring security 配置类加载 ####WebSecurityConfigurerAdapter 一般我们在使用spring security作为我们安全验证的时候经常会编写配置类继承WebSecurityConfigurerAdapter，通过重写其中的config()类来自定义自己的安全验证流程。而HttpSecurity类则是其中非常重要的一个配置类，通过它你可以集成其他第三方的生态来满足自己的业务需求。 ####HttpSecurity 在HttpSecurity 中我们可以看到很多配置方法比如 HttpSecurit.java1234567891011public OpenIDLoginConfigurer&lt;HttpSecurity&gt; openidLogin() throws Exception { return getOrApply(new OpenIDLoginConfigurer&lt;&gt;()); } ...public HeadersConfigurer&lt;HttpSecurity&gt; headers() throws Exception { return getOrApply(new HeadersConfigurer&lt;&gt;()); } 很明显它们都调用了getOrAppley方法 HttpSecurit.java123456789101112private &lt;C extends SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt;&gt; C getOrApply( C configurer) throws Exception { //从已加载中的配置类根据class获取 C existingConfig = (C) getConfigurer(configurer.getClass()); //不为空的或就返回已加载类 if (existingConfig != null) { return existingConfig; } return apply(configurer); } 再看apply这个方法 AbstractConfiguredSecurityBuilder123456789101112public &lt;C extends SecurityConfigurerAdapter&lt;O, B&gt;&gt; C apply(C configurer) throws Exception { //添加后置处理器 configurer.addObjectPostProcessor(objectPostProcessor); //设置builder configurer.setBuilder((B) this); //把这个配置类添加到配置类集合中 add(configurer); return configurer; } 首先objectPostProcessor 应该是ObjectPostProcessorConfiguration这个配置类中的AutowireBeanFactoryObjectPostProcessor实例，它管理了一系列的SmartInitializingSingleton的afterSingletonsInstantiated方法和DisposableBean的destroy方法，以确保他们被调用。 configurer.setBuilder((B) this); 则是把builder类的引用放到配置类中（SecurityConfigurerAdapter子类）这样配置类就可以通过getbuilder()方法来实现一系列操作。 最后configer会被放入一个集合中通过doBuild()方法来进行加载初始化 AbstractConfiguredSecurityBuilder1234567891011121314151617181920212223242526protected final O doBuild() throws Exception { //加锁 synchronized (configurers) { buildState = BuildState.INITIALIZING; beforeInit(); init(); buildState = BuildState.CONFIGURING; beforeConfigure(); configure(); buildState = BuildState.BUILDING; O result = performBuild(); buildState = BuildState.BUILT; return result; } } 各种配置类有各自的实现，这样ss就可以扩展安全验证的机制了。","link":"/2019/04/22/ss-config1/"},{"title":"zsh","text":"###zsh 从 macOS Catalina 版开始，您的 Mac 将使用 zsh 作为默认登录 Shell 和交互式 Shell。您还可以在较低版本的 macOS 中将 zsh 设置为默认 Shell。 默认情况下，您的 Mac 使用 zsh 或 bash 作为登录 Shell 和交互式 Shell 的命令行解释器： 从 macOS Catalina Beta 版开始，zsh (Z shell) 是所有新建用户帐户的默认 Shell。bash 是 macOS Mojave 及更低版本中的默认 Shell。zsh 与 Bourne Shell (sh) 高度兼容，并且与 bash 基本兼容，但存在一些差别。要进一步了解 zsh 及其全面的命令行完成系统，请在“终端”中输入 man zsh。 在mac中打卡控制台会出现The default interactive shell is now zsh.To update your account to use zsh, please run chsh -s /bin/zsh.For more details, please visit https://support.apple.com/kb/HT208050. 打卡网址发现新添加了.zprofile 和 .zshrc那已经有了bash 为什么需要zsh? ######Licensing google了一下发现https://thenextweb.com/dd/2019/06/04/why-does-macos-catalina-use-zsh-instead-of-bash-licensing/ 里提到苹果好像是为了更换里面的licensing。原来用的是GUN的bash，协议GPLv3。 同时苹果可能会开始维护更新这个zsh了。","link":"/2019/10/14/zsh/"},{"title":"LINUX I/O 简介","text":"LINUX I/O 简介在linux中所有外部设备，进程，网络都可以看成一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个file descriptor(fd,文件描述符)。对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符)，描述符就是一个数字，它指向内核中的一个结构体（文件路径，数据区等一些属性）。 ####基本I/O与标准I/O 类unix系统中有直接对文件进行的操作函数read()/write()，这些被称为不带缓冲的I/O；标准I/O在基本的I/O函数基础上增加了流和缓冲的概念，常用的函数有fopen/getc()/putc()等，标准I/O使用了缓冲的机制，缓冲又分为全缓冲和行缓冲，引入缓冲机制主要是为了提供文件读写的性能和效率。 读文件调用getc()时,操作系统底层会使用read()函数，并从用户空间切换到内核空间，执行系统调用。首先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，经过两次数据拷贝过程，进程才能获取到文件内容。写操作也是一样，用户态写数据时，待发送数据所在的缓冲区处于内核空间，用户态不能直接访问，必须先拷贝至内核空间对应的主存，才能写回磁盘中（延迟写回），因此写入也是需要两次数据拷贝。 ####I/O模型 I/O阻塞模型 默认情况下，我们使用的都是阻塞I/O模型，在缺省情况下所有对文件的操作都是阻塞的。以套接字为例，在进程空间中调用recvfrom. If no messages are available at the socket, the receive calls wait for a message to arrive, unless the socket is nonblocking (see fcntl(2)), in which case the value -1 is returned and the external variable errno is set to EAGAIN or EWOULDBLOCK. 他会去等待信息返回且被复制到应用进程的缓冲区内或者发送错误并且发送到EAGAIN or EWOULDBLOCK. ，进程会在此期间一直等待。 非阻塞I/O模型 非阻塞IO模型下，我们发出open/read/write这样的IO操作时，这些操作不会永远阻塞，而是立即返回。对于一个给定的文件描述符，有两种指定非阻塞的方法： 1.调用open获得描述符时，可指定O_NONBLOCK标志。 2.对于一个已经打开的描述符，可调用fcntl，由该函数打开O_NONBLOCK状态标志。 非阻塞模型由于立即返回，后面需要轮询不断的查看读写是否已经就绪，然后才能进行I/O操作 IO复用 Linux 提供select/poll,进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select操作上，这样select/poll可以帮我们侦测多个fd是否处于就绪状态。缺点：受FD_SETSIZE大小影响，优点：Linux 提供epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描,性能更高。 信号驱动I/O 需要开启套接口信号驱动I/O功能，系统通过调用sigaction执行一个信号处理函数（此系统调用立即返回，非阻塞）。当数据返回时生成一个SIGIO，通过信号回调通知应用系统调用recvfrom读取数据。 异步I/O 告知kernel启动某个操作，并让kernel在完成整个操作后（包括将数据从kernel复制到用户自己的缓存区）进行通知，与信号驱动模型的主要区别是信号驱动I/O有kernel通知何时开始，而异步I/O有kernel通知何时完成。 ####epoll epoll在2.5.44内核中被引进,epoll与select的原理比较相似，主要因为select一些固有的缺陷所有linux使用了epoll来代替select.而除了epoll，在freeBSD下还有kqueue,Solaris的/dev/poll.epoll 在文件描述符可进行 I/O 操作时进行通知，而 kqueue 和 IOCP 都在请求的操作完成时进行通知。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 ######epoll的优点 支持一个进程打开的socket描述符（fd）不受FD_SETSIZE限制(仅受限与操作系统的最大文件句柄数) I/O效率不会随着FD的数目的增加而线性下降 使用mmap加速内核与用户空间的消息传递（mmap是一种内存映射文件的方法，可以将一个文件或者其它对象映射到进程的虚拟地址空间，实现文件磁盘地址和进程虚拟地址空间中某一段地址的一一对映，这样应用程序就可以通过访问进程虚拟内存地地址直接访问到文件或对象。） epoll的api更加简单 来源netty netty权威指南","link":"/2019/04/18/year-month-day-LinuxIO-md/"},{"title":"Java Optional的用法","text":"关于Optional,平时项目用的不多.笔者觉得Java 引入Optional 主要用于解决参数时传递一些可能为空对象时产生的空指针问题. 1.使用Optional的一些问题 filterbad code:Demo.java1234optional.filter(s -&gt; StrUtil.isNotEmpty(s.getName())).orElseThrow(() -&gt; new IllegalParamException());optional.filter(s -&gt; StrUtil.isNotEmpty(s.getStartDate())).orElseThrow(() -&gt; new IllegalParamException());optional.filter(s -&gt; StrUtil.isNotEmpty(s.getEndDate())).orElseThrow(() -&gt; new IllegalParamException());optional.filter(s -&gt; s.getStartDate().compareTo(s.getEndDate()) &lt;= 0).orElseThrow(() -&gt; new IllegalParamException());影响整体代码的阅读和可扩展性,使用if语句判断或者spring validator 来进行参数校验可能会更好. good codeDemo.java12345optional.filter(s -&gt; StrUtil.isNotEmpty(s.getGroupName())) .filter(s -&gt; StrUtil.isNotEmpty(s.getStartDate())) .filter(s -&gt; StrUtil.isNotEmpty(s.getEndDate())) .filter(s -&gt; s.getStartDate().compareTo(s.getEndDate()) &lt;= 0) .orElseThrow(() -&gt; new IllegalParamException());缺点是不能根据具体的参数返回对应的错误信息. Optional.java1234567public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) { Objects.requireNonNull(predicate); if (!isPresent()) return this; else return predicate.test(value) ? this : empty(); } filter 先判断当前Optional是否有值,如果存在就使用predicate判断是否符合条件,如果不通过就返回一个空的Optional. 2.使用Optional的一些问题 map往往在对接第三方服务时会使用多层嵌套结构 比如 Company -&gt; Department -&gt; Team -&gt; User bad codeDemo.java123456if (company != null) { Department dep = company.getDepartment(); if (dep != null) { ... }}good codeDemo.java123456Optional.ofNullable(Company) .map(c -&gt; c.getDepartment()) .map(d -&gt; d.getTeam()) .map(t -&gt; t.getUser()) .orElseThrow(NoSuchElementException::new); map 和 filter 一样,只有当前optional里的值不为空才会去执行对应的函数表达式,原理和if一样但是更简洁. Optional.java123456789public&lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; mapper) { Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else { return Optional.ofNullable(mapper.apply(value)); }} orElse 和 orElseGet的区别 Optional.java1234567public T orElse(T other) { return value != null ? value : other; } public T orElseGet(Supplier&lt;? extends T&gt; other) { return value != null ? value : other.get(); } 2个方法的参数不同,如果传入的参数为固定的值或者对象,那么2个方法的处理和返回没有任何区别.但是当传入的是表达式时,orElse会首先执行表达式获得结果,然后入栈.而 orElseGet 的参数是 Supplier,所以直接入栈,然后在调用 other.get()的时候才会被触发.明显在特殊情况下后者的性能更好.","link":"/2021/08/10/optional/"},{"title":"GROUP BY分组查询与SQL执行顺序","text":"转自：http://blog.163.com/shexinyang@126/blog/static/1367393122013526113822666/ 1.SELECT语句使用GROUP BY的一些规定 GROUP BY子句可以包含任意数目的列。也就是说可以在组里再分组，为数据分组提供更细致的控制。 如果在GROUP BY子句中指定多个分组，数据将在最后指定的分组上汇总。 GROUP BY子句中列出的每个列都必须是检索列或有效的表达式（但不能是聚集函数）。如果在SELECT中使用了表达式，则必须在GROUP BY子句中指定相同的表达式。不能使用别名。 除了聚集计算语句外，GROUP BY子句中的每一列都必须在SELECT语句给出。 如果分组列中有NULL值，则NULL将作为一个分组返回。如果有多行NULL值，它们将分为一组。 GROUP BY子句必须在WHERE子句之后，ORDER BY之前。 2.过滤分组对分组过于采用HAVING子句。HAVING子句支持所有WHERE的操作。HAVING与WHERE的区别在于WHERE是过滤行的，而HAVING是用来过滤分组。 另一种理解WHERE与HAVING的区别的方法是，WHERE在分组之前过滤，而HAVING在分组之后以每组为单位过滤。 3.分组与排序一般在使用GROUP BY子句时，也应该使用ORDER BY子句。这是保证数据正确排序的唯一方法。 SQL SELECT语句的执行顺序： from子句组装来自不同数据源的数据(若有join，则先执行on后条件，再连接数据源)；where子句基于指定的条件对记录行进行筛选；group by子句将数据划分为多个分组；使用聚集函数进行计算；使用having子句筛选分组；计算所有的表达式；使用order by对结果集进行排序；select 集合输出。","link":"/2021/08/08/sql-group-by/"},{"title":"DirectByteBuffer","text":"堆外内存DirectByteBufferDirectByteBuffer是jdk提供的访问对外内存的一种实现，堆外内存的优势在于，1.使用socket网络传输时，它能够节省堆内存到堆外内存的复制消耗。2.对于磁盘io,可以使用内存映射，提高效率。3.不需要考虑gc问题。它并不受jvm内存管理,所有当对外内存不足时，系统会显式地调用一次System.gc()，如果还是不能申请到足够内存，系统就会报出 12java.lang.OutOfMemoryError: Direct buffer memory 如果我们在jvm参数上加上 -XX:+DisableExplicitGC 那么就会使显式gc无效。同时我们也可以通过增大-XX:MaxDirectMemorySize来增加堆外内存 下面看一下DirectByteBuffer的创建DirectByteBuffer.java1234567891011121314151617181920212223242526272829303132333435DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); //是否对齐 boolean pa = VM.isDirectMemoryPageAligned(); //默认每页的大小 int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); //在申请或者释放内存时都应该调用 里面通过CAS来count //在这个方法中 如果检测到内存不够就会显式调用system.gc() Bits.reserveMemory(size, cap); long base = 0; try { //调用jni申请内存 base = UNSAFE.allocateMemory(size); } catch (OutOfMemoryError x) { //cas 减少数量 Bits.unreserveMemory(size, cap); throw x; } UNSAFE.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); } else { address = base; } //添加cleaner 用于回收内存 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; 在看下Cleaner,它继承了PhantomReference。 PhantomReference的作用在于跟踪垃圾回收过程 Phantom reference objects, which are enqueued after the collector determines that their referents may otherwise be reclaimed. Reference中有个ReferenceHandler 它会一直检测getAndClearReferencePendingList()获得的list, Reference.java1234567891011121314151617181920212223242526272829303132333435363738private static void processPendingReferences() { // Only the singleton reference processing thread calls // waitForReferencePendingList() and getAndClearReferencePendingList(). // These are separate operations to avoid a race with other threads // that are calling waitForReferenceProcessing(). waitForReferencePendingList(); Reference&lt;Object&gt; pendingList; synchronized (processPendingLock) { pendingList = getAndClearReferencePendingList(); processPendingActive = true; } while (pendingList != null) { Reference&lt;Object&gt; ref = pendingList; pendingList = ref.discovered; ref.discovered = null; //这里如果ref是Cleaner 就会调用它的clean()方法 if (ref instanceof Cleaner) { ((Cleaner)ref).clean(); // Notify any waiters that progress has been made. // This improves latency for nio.Bits waiters, which // are the only important ones. synchronized (processPendingLock) { processPendingLock.notifyAll(); } } else { ReferenceQueue&lt;? super Object&gt; q = ref.queue; if (q != ReferenceQueue.NULL) q.enqueue(ref); } } // Notify any waiters of completion of current round. synchronized (processPendingLock) { processPendingActive = false; processPendingLock.notifyAll(); } } 而cleaner会调用Deallocator里面的 DirectByteBuffer.java1234567891011public void run() { if (address == 0) { // Paranoia return; } //释放内存 UNSAFE.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); } netty堆外内存AbstractByteBufAllocator protected abstract ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity); 在它的实现里有池化和非池化，这里主要介绍池化策略。 PooledByteBufAllocatorPooledByteBufAllocator采用的是jemalloc来进行内存分配。jemalloc将内存划分为一个个Arena，而在PooledByteBufAllocator里面，程序维护了heapArenas和directArenas，分别代表堆内和堆外Arena。每个Arena又有多个chunk组成。可以看到PoolArena中有PoolChunkList - 存储chunk，SizeClass枚举类 - 对分配内存的大小作区分，tinySubpagePools - 用来保存为tiny规格分配的内存页的链表， smallSubpagePools -用来保存为small规格分配的内存页的链表。 PooledByteBufAllocator.java123456789101112131415161718@Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) { PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena; final ByteBuf buf; if (directArena != null) { //分配内存 buf = directArena.allocate(cache, initialCapacity, maxCapacity); } else { buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); } return toLeakAwareBuffer(buf); } PoolArena.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T&gt; buf, final int reqCapacity) { //计算大小 final int normCapacity = normalizeCapacity(reqCapacity); //根据大小选择不同的PoolSubpage 和 allocate if (isTinyOrSmall(normCapacity)) { // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T&gt;[] table; boolean tiny = isTiny(normCapacity); if (tiny) { // &lt; 512 //具体allocate if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } //计算出索引 tableIdx = tinyIdx(normCapacity); table = tinySubpagePools; } else { if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } tableIdx = smallIdx(normCapacity); table = smallSubpagePools; } //准备放到对应的page数组中 final PoolSubpage&lt;T&gt; head = table[tableIdx]; /** * Synchronize on the head. This is needed as {@link PoolChunk#allocateSubpage(int)} and * {@link PoolChunk#free(long)} may modify the doubly linked list as well. */ synchronized (head) { final PoolSubpage&lt;T&gt; s = head.next; if (s != head) { assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle &gt;= 0; s.chunk.initBufWithSubpage(buf, null, handle, reqCapacity); incTinySmallAllocation(tiny); return; } } synchronized (this) { allocateNormal(buf, reqCapacity, normCapacity); } incTinySmallAllocation(tiny); return; } if (normCapacity &lt;= chunkSize) { //在缓存外分配 if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) { // was able to allocate out of the cache so move on return; } synchronized (this) { allocateNormal(buf, reqCapacity, normCapacity); ++allocationsNormal; } } else { // Huge allocations are never served via the cache so just call allocateHuge allocateHuge(buf, reqCapacity); } } 我们可以看到分配内存的信息会被保存在Aerna的chunk和page对应链表中。同时它会根据请求分配的大小选择不同的chunk和page. 参考堆外内存之 DirectByteBuffer 详解 涤生","link":"/2019/04/28/DirectByteBuffer/"},{"title":"SpringBean","text":"关于spring bean的实例化和初始化流程的一些记录 1.BeanDedifinition的beanClass设置当想要去创建bean时,是想创建BeanDedifinition,而在BeanDedifinition创建完之后,Bean实例化之前BeanDedifinition的beanClass由String类型转成对应Bean的class类型,而ClassLoader则是由当前线程的ClassLoader(AppClassLoader)进行加载. 那beanClass为什么是String类型的.AbstractBeanDefinition.java1234@Override public void setBeanClassName(@Nullable String beanClassName) { this.beanClass = beanClassName; }这里设置BeanClassName时默认设置beanClass为类名.那我们在实例化bean时必须先把beanClass转换成对应的class对象.对应的设置的方法为AbstractBeanFactory的resolveBeanClass方法.在方法里又调用了doResolveBeanClass方法,里面先获取ClassLoader,之后调用AbstractBeanDefinition的resolveBeanClass方法.在这个方法里通过ClassLoader它设置我们beanClass. AbstractBeanFactory.java123456789101112@Nullable private Class&lt;?&gt; doResolveBeanClass(RootBeanDefinition mbd, Class&lt;?&gt;... typesToMatch) throws ClassNotFoundException { ClassLoader beanClassLoader = getBeanClassLoader(); ClassLoader dynamicLoader = beanClassLoader; boolean freshResolve = false; // 省略部分代码 .... return mbd.resolveBeanClass(beanClassLoader); } 在这里设置beanClass.AbstractBeanDefinition.java1234567891011@Nullable public Class&lt;?&gt; resolveBeanClass(@Nullable ClassLoader classLoader) throws ClassNotFoundException { String className = getBeanClassName(); if (className == null) { return null; } Class&lt;?&gt; resolvedClass = ClassUtils.forName(className, classLoader); this.beanClass = resolvedClass; return resolvedClass; } spring aware 接口回调 首先创建bean AbstractAutowireCapableBeanFactory.java12345678910111213141516171819202122232425protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // Instantiate the bean. BeanWrapper instanceWrapper = null; // 如果是单例就不用重复实例化了 if (mbd.isSingleton()) { instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); } if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } //其他步骤 ... try { // 设置bean的属性 populateBean(beanName, mbd, instanceWrapper); // 初始化bean exposedObject = initializeBean(beanName, exposedObject, mbd); } } 在AbstractAutowireCapableBeanFactory的initializeBean方法中实现了对spring中Aware的回调 AbstractAutowireCapableBeanFactory.java12345678910111213141516171819202122232425262728293031protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { invokeAwareMethods(beanName, bean); return null; }, getAccessControlContext()); } else { invokeAwareMethods(beanName, bean); } Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } try { invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); } if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean; } 这个方法中首先判断安全,然后调用invokeAwareMethods 这个方法AbstractAutowireCapableBeanFactory.java1234567891011121314151617private void invokeAwareMethods(final String beanName, final Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ClassLoader bcl = getBeanClassLoader(); if (bcl != null) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } } } 这个方法依次调用了BeanNameAware, BeanClassLoaderAware, BeanFactoryAware.这里并没有调用ApplicationContextAware,因为这里是初始化bean相关的回调. ApplicationContextAware回调在applyBeanPostProcessorsBeforeInitialization方法中进行. 再来看下applyBeanPostProcessorsBeforeInitialization AbstractAutowireCapableBeanFactory.java1234567891011121314@Override public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) { Object current = processor.postProcessBeforeInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } 通过获取beanfactory里面的BeanPostProcessors 然后调用postProcessBeforeInitialization.如果我们的BeanPostProcessors中包含了ApplicationContextAwareProcessor(这是一个内部类),那么spring便会实现ApplicationContextAware回调. ApplicationContextAwareProcessor.java12345678910111213141516171819202122public Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { invokeAwareInterfaces(bean); return null; }, acc); } else { invokeAwareInterfaces(bean); } return bean; } 这里面回调了关于application context上下文的Aware接口ApplicationContextAwareProcessor.java12345678910111213141516171819202122private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } } } 我们再回到initializeBean方法 ,在applyBeanPostProcessorsBeforeInitialization方法之后调用了invokeInitMethods方法.里面先调用了实现InitializingBean的afterPropertiesSet方法,之后如果bean有InitMethod就调用它.AbstractAutowireCapableBeanFactory.java123456789101112131415161718192021222324252627282930313233protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable { boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) { if (logger.isTraceEnabled()) { logger.trace(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); } if (System.getSecurityManager() != null) { try { AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; { ((InitializingBean) bean).afterPropertiesSet(); return null; }, getAccessControlContext()); } catch (PrivilegedActionException pae) { throw pae.getException(); } } else { ((InitializingBean) bean).afterPropertiesSet(); } } if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) { String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) { invokeCustomInitMethod(beanName, bean, mbd); } } } 最后applyBeanPostProcessorsAfterInitialization主要回调BeanPostProcessor.postProcessAfterInitialization方法,例如ApplicationListener Bean初始化之后,ApplicationListenerDetector在此阶段将其添加到applicationContext. AbstractAutowireCapableBeanFactory.java1234567891011121314@Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) { Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; }","link":"/2021/07/23/SpringBean/"},{"title":"研究 Dubbo 网卡地址注册时的一点思考","text":"曾使用k8s部署dubbo服务时使用虚拟ip会导致consumer不能找到对应的provider。 转自https://dubbo.apache.org/zh/blog/2019/10/01/%E7%A0%94%E7%A9%B6-dubbo-%E7%BD%91%E5%8D%A1%E5%9C%B0%E5%9D%80%E6%B3%A8%E5%86%8C%E6%97%B6%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/ 问题：dubbo注册自身ip的问题原文:可能相当一部分人还不知道我这篇文章到底要讲什么，我说个场景，大家应该就明晰了。在分布式服务调用过程中，以 Dubbo 为例，服务提供者往往需要将自身的 IP 地址上报给注册中心，供消费者去发现。在大多数情况下 Dubbo 都可以正常工作，但如果你留意过 Dubbo 的 github issue，其实有不少人反馈：Dubbo Provider 注册了错误的 IP。如果你能立刻联想到：多网卡、内外网地址共存、VPN、虚拟网卡等关键词，那我建议你一定要继续将本文看下去，因为我也想到了这些，它们都是本文所要探讨的东西！那么“如何选择合适的网卡地址”呢，Dubbo 现有的逻辑到底算不算完备？我们不急着回答它，而是带着这些问题一起进行研究，相信到文末，其中答案，各位看官自有评说。 NetUtils.java12345678910111213141516171819202122232425262728293031323334353637383940#这里使用的是阿里的2.6.10版本private static InetAddress getLocalAddress0() { InetAddress localAddress = null; try { localAddress = InetAddress.getLocalHost(); if (isValidAddress(localAddress)) { return localAddress; } } catch (Throwable e) { logger.warn(e); } try { Enumeration&lt;NetworkInterface&gt; interfaces = NetworkInterface.getNetworkInterfaces(); if (interfaces != null) { while (interfaces.hasMoreElements()) { try { NetworkInterface network = interfaces.nextElement(); Enumeration&lt;InetAddress&gt; addresses = network.getInetAddresses(); if (addresses != null) { while (addresses.hasMoreElements()) { try { InetAddress address = addresses.nextElement(); if (isValidAddress(address)) { return address; } } catch (Throwable e) { logger.warn(e); } } } } catch (Throwable e) { logger.warn(e); } } } } catch (Throwable e) { logger.warn(e); } return localAddress; } NetUtils.java1234567891011121314151617181920212223242526272829303132333435363738#这里使用的是apache的3.2.0版本private static InetAddress getLocalAddress0() { InetAddress localAddress = null; // @since 2.7.6, choose the {@link NetworkInterface} first try { NetworkInterface networkInterface = findNetworkInterface(); Enumeration&lt;InetAddress&gt; addresses = networkInterface.getInetAddresses(); while (addresses.hasMoreElements()) { Optional&lt;InetAddress&gt; addressOp = toValidAddress(addresses.nextElement()); if (addressOp.isPresent()) { try { if (addressOp.get().isReachable(100)) { return addressOp.get(); } } catch (IOException e) { // ignore } } } } catch (Throwable e) { logger.warn(e); } try { localAddress = InetAddress.getLocalHost(); Optional&lt;InetAddress&gt; addressOp = toValidAddress(localAddress); if (addressOp.isPresent()) { return addressOp.get(); } } catch (Throwable e) { logger.warn(e); } return localAddress; } Dubbo 这段选取本地地址的逻辑大致分成了两步 1.先去 /etc/hosts 文件中找 hostname 对应的 IP 地址，找到则返回；找不到则转2.轮询网卡，寻找合适的 IP 地址，找到则返回；找不到返回 null，在 getLocalAddress0 外侧还有一段逻辑，如果返回 null，则注册 127.0.0.1 这个本地回环地址 这里与原文的区别在于都使用了try catch捕获了异常 尝试获取 hostname 映射 IPDubbo 首先选取的是 hostname 对应的 IP，在源码中对应的 InetAddress.getLocalHost(); 在 *nix 系统实际部署 Dubbo 应用时，可以首先使用 hostname 命令获取主机名 原文:12xujingfengdeMacBook-Pro:~ xujingfeng$ hostnamexujingfengdeMacBook-Pro.local 紧接着在 /etc/hosts 配置 IP 映射，为了验证 Dubbo 的机制，我们随意为 hostname 配置一个 IP 地址 12127.0.0.1 localhost1.2.3.4 xujingfengdeMacBook-Pro.local 接着调用 NetUtils.getLocalAddress0() 进行验证，控制台打印如下：1xujingfengdeMacBook-Pro.local/1.2.3.4 我在本地使用 阿里的版本12ygdxd_admin$ hostnamelocalhost debug时InetAddress.getLocalHost() 会返回localhost/127.0.0.1因为使用不了localhost所以不会返回 1System.out.println(NetUtils.getLocalAddress().toString()); 返回的是/192.168.0.102 使用debug 发现使用的是eh0的网卡地址 判定有效的 IP 地址NetUtils.java123456789101112private static Optional&lt;InetAddress&gt; toValidAddress(InetAddress address) { if (address instanceof Inet6Address) { Inet6Address v6Address = (Inet6Address) address; if (isValidV6Address(v6Address)) { return Optional.ofNullable(normalizeV6Address(v6Address)); } } if (isValidV4Address(address)) { return Optional.of(address); } return Optional.empty();} 阿里的版本直接去掉了ipv6的验证 NetUtils.java123456789private static boolean isValidAddress(InetAddress address) { if (address == null || address.isLoopbackAddress()) return false; String name = address.getHostAddress(); return (name != null &amp;&amp; !ANYHOST.equals(name) &amp;&amp; !LOCALHOST.equals(name) &amp;&amp; IP_PATTERN.matcher(name).matches()); } 原文：123456789101112static boolean isValidV6Address(Inet6Address address) { boolean preferIpv6 = Boolean.getBoolean(\"java.net.preferIPv6Addresses\"); if (!preferIpv6) { return false; } try { return address.isReachable(100); } catch (IOException e) { // ignore } return false;} 最新的apache dubbo 版本123456789101112private static Optional&lt;InetAddress&gt; toValidAddress(InetAddress address) { if (address instanceof Inet6Address) { Inet6Address v6Address = (Inet6Address) address; if (isPreferIPV6Address()) { return Optional.ofNullable(normalizeV6Address(v6Address)); } } if (isValidV4Address(address)) { return Optional.of(address); } return Optional.empty(); } 已经取消掉了通过 isReachable 判断网卡的连通性,而在轮训网卡中使用了1234567891011121314151617181920212223242526272829303132333435363738394041424344public static NetworkInterface findNetworkInterface() { List&lt;NetworkInterface&gt; validNetworkInterfaces = emptyList(); try { validNetworkInterfaces = getValidNetworkInterfaces(); } catch (Throwable e) { logger.warn(e); } NetworkInterface result = null; // Try to find the preferred one for (NetworkInterface networkInterface : validNetworkInterfaces) { if (isPreferredNetworkInterface(networkInterface)) { result = networkInterface; break; } } if (result == null) { // If not found, try to get the first one for (NetworkInterface networkInterface : validNetworkInterfaces) { Enumeration&lt;InetAddress&gt; addresses = networkInterface.getInetAddresses(); while (addresses.hasMoreElements()) { Optional&lt;InetAddress&gt; addressOp = toValidAddress(addresses.nextElement()); if (addressOp.isPresent()) { try { if (addressOp.get().isReachable(100)) { result = networkInterface; break; } } catch (IOException e) { // ignore } } } } } if (result == null) { result = first(validNetworkInterfaces); } return result; } 轮询网卡轮询网卡对应的源码是 NetworkInterface.getNetworkInterfaces(). 这里记录下干扰因素 1.Docker 网桥2.TUN/TAP 虚拟网络设备3.干扰因素三：多网卡 记录下网卡工作原理 上图中的 eth0 表示我们主机已有的真实的网卡接口 (interface)。 网卡接口 eth0 所代表的真实网卡通过网线(wire)和外部网络相连，该物理网卡收到的数据包会经由接口 eth0 传递给内核的网络协议栈(Network Stack)。然后协议栈对这些数据包进行进一步的处理。 对于一些错误的数据包,协议栈可以选择丢弃；对于不属于本机的数据包，协议栈可以选择转发；而对于确实是传递给本机的数据包,而且该数据包确实被上层的应用所需要，协议栈会通过 Socket API 告知上层正在等待的应用程序。 TUN 工作原理 我们知道，普通的网卡是通过网线来收发数据包的话，而 TUN 设备比较特殊，它通过一个文件收发数据包。 如上图所示，tunX 和上面的 eth0 在逻辑上面是等价的， tunX 也代表了一个网络接口,虽然这个接口是系统通过软件所模拟出来的. 网卡接口 tunX 所代表的虚拟网卡通过文件 /dev/tunX 与我们的应用程序(App)相连，应用程序每次使用 write 之类的系统调用将数据写入该文件，这些数据会以网络层数据包的形式，通过该虚拟网卡，经由网络接口 tunX 传递给网络协议栈，同时该应用程序也可以通过 read 之类的系统调用，经由文件 /dev/tunX 读取到协议栈向 tunX 传递的所有数据包。 此外，协议栈可以像操纵普通网卡一样来操纵 tunX 所代表的虚拟网卡。比如说，给 tunX 设定 IP 地址，设置路由，总之，在协议栈看来，tunX 所代表的网卡和其他普通的网卡区别不大，当然，硬要说区别，那还是有的,那就是 tunX 设备不存在 MAC 地址，这个很好理解，tunX 只模拟到了网络层，要 MAC地址没有任何意义。当然，如果是 tapX 的话，在协议栈的眼中，tapX 和真实网卡没有任何区别。 是不是有些懵了？我是谁，为什么我要在这篇文章里面学习 TUN！因为我们常用的 VPN 基本就是基于 TUN/TAP 搭建的，如果我们使用 TUN 设备搭建一个基于 UDP 的 VPN ，那么整个处理过程可能是这幅样子： TAP 工作原理TAP 设备与 TUN 设备工作方式完全相同，区别在于： TUN 设备是一个三层设备，它只模拟到了 IP 层，即网络层 我们可以通过 /dev/tunX 文件收发 IP 层数据包，它无法与物理网卡做 bridge，但是可以通过三层交换（如 ip_forward）与物理网卡连通。可以使用ifconfig之类的命令给该设备设定 IP 地址。TAP 设备是一个二层设备，它比 TUN 更加深入，通过 /dev/tapX 文件可以收发 MAC 层数据包，即数据链路层，拥有 MAC 层功能，可以与物理网卡做 bridge，支持 MAC 层广播。同样的，我们也可以通过ifconfig之类的命令给该设备设定 IP 地址，你如果愿意，我们可以给它设定 MAC 地址。关于文章中出现的二层，三层，我这里说明一下，第一层是物理层，第二层是数据链路层，第三层是网络层，第四层是传输层。","link":"/2021/09/14/dubbo-net/"},{"title":"虚拟地址转换流程","text":"转载自https://zhuanlan.zhihu.com/p/65298260?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=983771259783606272 在Linux，Windows等操作系统中，为什么不直接使用Physical Address（物理地址），而要用Virtual Address（虚拟地址）呢（在intel的手册中也被称为Linear Address，具体原因请参考这篇文章）？https://zhuanlan.zhihu.com/p/67576012 因为使用虚拟地址可以带来诸多好处： 1.在支持多进程的系统中，如果各个进程的镜像文件都使用物理地址，则在加载到同一物理内存空间的时候，可能发生冲突。2.直接使用物理地址，不便于进行进程地址空间的隔离。3.物理内存是有限的，在物理内存整体吃紧的时候，可以让多个进程通过分时复用的方法共享一个物理页面（某个进程需要保存的内容可以暂时swap到外部的disk/flash），这有点类似于多线程分时复用共享CPU的方式。既然使用虚拟地址，就涉及到将虚拟地址转换为物理地址的过程，这需要MMU（Memory Management Unit）和页表（page table）的共同参与。 MMUMMU是处理器/核（processer）中的一个硬件单元，通常每个核有一个MMU。MMU由两部分组成：TLB(Translation Lookaside Buffer)和table walk unit。 Page Tablepage table是每个进程独有的，是软件实现的，是存储在main memory（比如DDR）中的。 Address Translation因为访问内存中的页表相对耗时，尤其是在现在普遍使用多级页表的情况下，需要多次的内存访问，为了加快访问速度，系统设计人员为page table设计了一个硬件缓存 - TLB，CPU会首先在TLB中查找，因为在TLB中找起来很快。TLB之所以快，一是因为它含有的entries的数目较少，二是TLB是集成进CPU的，它几乎可以按照CPU的速度运行。 如果在TLB中找到了含有该虚拟地址的entry（TLB hit），则可从该entry【1】中直接获取对应的物理地址，否则就不幸地TLB miss了，就得去查找当前进程的page table（这里其实可能用到paging structure caches）。这个时候，组成MMU的另一个部分table walk unit就被召唤出来了，这里面的table就是page table。 使用table walk unit硬件单元来查找page table的方式被称为hardware TLB miss handling，通常被CISC架构的处理器（比如IA-32）所采用。它要在page table中查找不到，出现page fault的时候才会交由软件（操作系统）处理。 与之相对的通常被RISC架构的处理器（比如Alpha）采用的software TLB miss handling，TLB miss后CPU就不再参与了，由操作系统通过软件的方式来查找page table。使用硬件的方式更快，而使用软件的方式灵活性更强。IA-64提供了一种混合模式，可以兼顾两者的优点。 如果在page table中找到了该虚拟地址对应的entry的p（present）位是1，说明该虚拟地址对应的物理页面当前驻留在内存中，也就是page table hit。找到了还没完，接下来还有两件事要做： 既然是因为在TLB里找不到才找到这儿来的，自然要更新TLB。进行权限检测，包括可读/可写/可执行权限，user/supervisor模式权限等。如果没有正确的权限，将触发SIGSEGV（Segmantation Fault）。如果该虚拟地址对应的entry的p位是0，就会触发page fault，可能有这几种情况： 这个虚拟地址被分配后还从来没有被access过（比如malloc之后还没有操作分配到的空间，则不会真正分配物理内存）。触发page fault后分配物理内存，也就是demand paging，有了确定的demand了之后才分，然后将p位置1。对应的这个物理页面的内容被换出到外部的disk/flash了，这个时候page table entry里存的是换出页面在外部swap area里暂存的位置，可以将其换回物理内存，再次建立映射，然后将p位置1。关于在TLB中具体是怎么找的，在page table中又是怎么”walk”的，请看下回分解。 注【1】：entry有入口的意思，对于TLB和单级页表的一个entry，就是指向对应page的首地址（入口）；对于后文介绍的多级页表的一个entry，就是指向下一级页表的首地址（入口）。 具体实现关于在TLB中具体是怎么找的，在page table中又是怎么”walk”的问题，下面通过一个简单的例子说明一下。假设当前CPU支持的虚拟地址是14位，物理地址是12位，page size为64字节（这里要说明一下，通常情况下呢，虚拟地址和物理地址的位数是一样的，但其实并不一定需要一样，因为本来就可以多个虚拟地址指向同一个物理地址嘛）。 不管是虚拟地址还是物理地址，因为最小管理单位都是page，在转换过程中，代表page内的偏移地址（offset）的低位bits部分是不需要参与的，需要转换的只是代表page唯一性标识的高位bits部分，称作page number。由此产生了4个概念：VPN（virtual page number），PPN（physical page number），VPO（virtual page offset）和PPO（physical page offset） VPO和PPO占的bit位数为 [公式] ，p为page size大小，即64，因而VPO和PPO的值为6。因为所有pages都是同样大小的，所以VPO始终等于PPO。 虚拟地址中剩下的bit位就成了VPN，物理地址中剩下的bit位就成了PPN。 假设我们的TLB一共有16个entries，是4路组相关（4-way set associative）的，则有16/4=4个sets。TLB本身就是一个hardware cache, 关于cache中way, set, index, tag的基础概念，如果还不熟悉的，可以参考这两篇文章：浅谈Cache Memory和cache之虚虚实实。http://www.wowotech.net/memory_management/458.htmlhttps://zhuanlan.zhihu.com/p/65024512 TLB Index（以下简称TI）的值为 [公式] =2，剩下的bit位就成了TLB Tag（以下简称TT）。 下面，我们准备读取虚拟地址为0x0334处的内容。 将这一地址分割成VPN和VPO 将VPN分割成TT和TI 使用TT (0x03) 和TI (0) 在TLB中查找。一个TLB entry的构成如下： 作为cache，TLB index是用来索引的，不会存储在TLB entry中，TLB entry中存的只有tag, 权限位，有效位和内容（对于TLB来说就是PPN）。 假设现在TLB中的内容是这样的（这里为了简化，省略了permission bits）： 虽然在set/index为0这一行，找到了tag为03的一个entry，但这个entry中PPN是不存在的，整个entry目前是invalid的，也就是说TLB miss了，需要去page table中找。 使用VPN (0x0C) 作为index在page table中查找。一个只有one level的page table（单级页表）构成如下： index作为索引，也是不会存储于page table entry中的，PTE存的只有权限位，有效位和内容（对于PTE来说也是PPN）。 假设现在的page table是这样的（同样为了简化，省略了permission bits）： 对应的PTE（page table entry）中的PPN不存在，依然是invalid的，这将触发一个page fault。 实现的细节展开后，上文中的图也可以展开了（只用关注左半部分） 对比一下，你可能会发现一个TLB entry比一个page table entry多了一个tag，TLB使用的是tag比对【1】，而页表使用的是index索引，在PTE数目很大的情况下这会带来一系列问题，详情请看下回分解。 注【1】：如果是full associative的TLB，则只有tag没有index；如果是n-way set associative的TLB，则先通过index索引，再进行tag比对。 说明：本文例子来源于https://courses.cs.washington.edu/courses/cse351/16wi/sections/8/cse351_16wi_08.pdf","link":"/2021/09/19/linux-virtual-addr/"},{"title":"rocketmq1","text":"rocketmq namesrvNamesrv简介namesrc 即 NameServer,类似于服务注册中心，它是RocketMq的调度中心，它提供了路由管理，服务注册及服务发现，服务剔除等服务。正是由于它，系统可以迅速地感知消息服务器的健康状况，对消息服务器的单点故障做出反应防止整个系统瘫痪。它还可以对消息进行负载均衡处理防止Broker宕机。 启动NamesrvNamesrvStartup.java123456789101112131415161718public static NamesrvController main0(String[] args) { try { NamesrvController controller = createNamesrvController(args); start(controller); String tip = \"The Name Server boot success. serializeType=\" + RemotingCommand.getSerializeTypeConfigInThisServer(); log.info(tip); System.out.printf(\"%s%n\", tip); return controller; } catch (Throwable e) { e.printStackTrace(); System.exit(-1); } return null; } 第一行createNamesrvController(args)根据参数创建一个NamesrvController实例，然后就这个实例当做参数调用start()方法，最后输出日志。先看start(final NamesrvController controller)方法 NamesrvStartup.java12345678910111213141516171819public static NamesrvController start(final NamesrvController controller) throws Exception {...boolean initResult = controller.initialize();...Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() { @Override public Void call() throws Exception { controller.shutdown(); return null; } })); controller.start(); return controller; } 可以看到它先调用了controller.initialize();这个条语句。然后给系统增加了一个关闭的钩子 在系统关闭之前回去调用controller的shutdown()方法。最后调用controller.start(). 可以看出这个NamesrvController就是整个启动过程关键类，而createNamesrvController(args)是生成它的方法。 NamesrvStartup.java123456789101112131415161718192021222324252627282930313233...//首先解析命令Options options = ServerUtil.buildCommandlineOptions(new Options()); commandLine = ServerUtil.parseCmdLine(\"mqnamesrv\", args, buildCommandlineOptions(options), new PosixParser()); ...//生成业务配置实例final NamesrvConfig namesrvConfig = new NamesrvConfig();//生成netty远程通信配置实例final NettyServerConfig nettyServerConfig = new NettyServerConfig();...//命令上-c 参数 系统会去读取配置文件并设置到NamesrvConfig中if (commandLine.hasOption('c')) {InputStream in = new BufferedInputStream(new FileInputStream(file));...namesrvConfig.setConfigStorePath(file);}//-p 参数也会设置if (commandLine.hasOption('p')) {...}...//logback 设置JoranConfigurator configurator = new JoranConfigurator();configurator.doConfigure(namesrvConfig.getRocketmqHome() + \"/conf/logback_namesrv.xml\");...最后生成NamesrvController 实例final NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig); // remember all configs to prevent discardcontroller.getConfiguration().registerConfig(properties); 可以看到NamesrvController 中有2个关键的配置类。 NamesrvConfig和NettyServerConfigNamesrvConfig。一个业务配置类，在类中有rocketmqHome（根目录，通过读取环境变量来设置）kvConfigPath 对应 kvConfig.json，NameServer存储KV配置属性的持久化路径。configStorePath 对应namesrv.properties，nameServer默认配置文件路径。orderMessageEnable，是否支持顺序消息，默认不支持。productEnvName 生产环境名称 NettyServerConfig。通信配置类listenPort：netty监听端口serverWorkerThreads： netty业务线程池数量serverCallbackExecutorThreads： netty public 任务线程池线程个数，默认为4个。用于处理消息发送，心跳检测等。serverSelectorThreads： IO线程池线程个数，主要是NameServer、Broker端解析请求的线程个数，这类线程主要是处理网络请求，解析请求包，然后转发到个业务线池完成具体的业务操作，然后将结果返回调用方。serverOnewaySemaphoreValue：send oneway 消息请求并发度（Broker端参数）serverAsyncSemaphoreValue：异步消息发送最大并发度（Boreker端参数）serverChannelMaxIdleTimeSeconds：网络连接最大空闲时间，默认120s。如果连接空闲时间超过该参数设置的值，连接将关闭。serverSocketSndBufSize：网络socket发送缓冲区大小，默认64k。serverSocketRcvBufSize：网络socket接受缓冲区大小，默认64k。serverPooledByteBufAllocatorEnable： ByteBuffer是否开启缓存，建议开启useEpollNativeSelector：是否启用Epoll IO模型，Linux环境建议开启。 NamesrvControllerNameServer控制类。里面包含了很多重要的配置和管理信息。前面通过namesrvConfig 和nettyServerConfig 初始化了一个NamesrvController实例。 NamesrvController.java12345678910111213this.namesrvConfig = namesrvConfig; this.nettyServerConfig = nettyServerConfig; this.kvConfigManager = new KVConfigManager(this); this.routeInfoManager = new RouteInfoManager(); this.brokerHousekeepingService = new BrokerHousekeepingService(this); this.configuration = new Configuration( log, this.namesrvConfig, this.nettyServerConfig ); this.configuration.setStorePathFromConfig(this.namesrvConfig, \"configStorePath\"); 这里还生成了一个路由信息管理类，一个broker下线的监听业务类BrokerHousekeepingService，用于连接改变时去更改this.routeInfoManager的路由信息。 ######RouteInfoManager的路由信息 RouteInfoManager.java12345678private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; topicQueueTable：Topic消息队列路由信息，消息发送时根据路由表进行负载均衡。brokerAddrTable：Broker基础信息，包含brokerName,所属集群名称，主备broker地址。clusterAddrTable：Broker集群信息，存储集群中所有的Broker名称。brokerLiveTable：Broker存活信息，NameServer每次收到心跳包时都会更新该信息。filterServerTable：过滤器列表。 而RouteInfoManager还拥有BrokerHousekeepingService的具体实现。 比如关闭连接 BrokerHousekeepingService.java1234@Override public void onChannelClose(String remoteAddr, Channel channel) { this.namesrvController.getRouteInfoManager().onChannelDestroy(remoteAddr, channel); } RouteInfoManager.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public void onChannelDestroy(String remoteAddr, Channel channel) { String brokerAddrFound = null; if (channel != null) { try { try { //获取读锁找到具体的broker信息 this.lock.readLock().lockInterruptibly(); Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; itBrokerLiveTable = this.brokerLiveTable.entrySet().iterator(); while (itBrokerLiveTable.hasNext()) { Entry&lt;String, BrokerLiveInfo&gt; entry = itBrokerLiveTable.next(); //找到 if (entry.getValue().getChannel() == channel) { brokerAddrFound = entry.getKey(); break; } } } finally { //解锁 this.lock.readLock().unlock(); } } catch (Exception e) { log.error(\"onChannelDestroy Exception\", e); } } if (null == brokerAddrFound) { brokerAddrFound = remoteAddr; } else { log.info(\"the broker's channel destroyed, {}, clean it's data structure at once\", brokerAddrFound); } if (brokerAddrFound != null &amp;&amp; brokerAddrFound.length() &gt; 0) { try { try { //加写锁，此时只有其余线程阻塞 this.lock.writeLock().lockInterruptibly(); //删除存活信息和对应的过滤器 this.brokerLiveTable.remove(brokerAddrFound); this.filterServerTable.remove(brokerAddrFound); String brokerNameFound = null; boolean removeBrokerName = false; //寻找对应的基础信息 Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable = this.brokerAddrTable.entrySet().iterator(); while (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) { BrokerData brokerData = itBrokerAddrTable.next().getValue(); Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator(); while (it.hasNext()) { Entry&lt;Long, String&gt; entry = it.next(); Long brokerId = entry.getKey(); String brokerAddr = entry.getValue(); if (brokerAddr.equals(brokerAddrFound)) { brokerNameFound = brokerData.getBrokerName(); //删除 it.remove(); log.info(\"remove brokerAddr[{}, {}] from brokerAddrTable, because channel destroyed\", brokerId, brokerAddr); break; } } if (brokerData.getBrokerAddrs().isEmpty()) { removeBrokerName = true; itBrokerAddrTable.remove(); log.info(\"remove brokerName[{}] from brokerAddrTable, because channel destroyed\", brokerData.getBrokerName()); } } if (brokerNameFound != null &amp;&amp; removeBrokerName) { Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator(); while (it.hasNext()) { Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next(); String clusterName = entry.getKey(); Set&lt;String&gt; brokerNames = entry.getValue(); boolean removed = brokerNames.remove(brokerNameFound); if (removed) { log.info(\"remove brokerName[{}], clusterName[{}] from clusterAddrTable, because channel destroyed\", brokerNameFound, clusterName); if (brokerNames.isEmpty()) { log.info(\"remove the clusterName[{}] from clusterAddrTable, because channel destroyed and no broker in this cluster\", clusterName); it.remove(); } break; } } } //在topick路由表进行更新 if (removeBrokerName) { Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable = this.topicQueueTable.entrySet().iterator(); while (itTopicQueueTable.hasNext()) { Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next(); String topic = entry.getKey(); List&lt;QueueData&gt; queueDataList = entry.getValue(); Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator(); while (itQueueData.hasNext()) { QueueData queueData = itQueueData.next(); if (queueData.getBrokerName().equals(brokerNameFound)) { itQueueData.remove(); log.info(\"remove topic[{} {}], from topicQueueTable, because channel destroyed\", topic, queueData); } } if (queueDataList.isEmpty()) { itTopicQueueTable.remove(); log.info(\"remove topic[{}] all queue, from topicQueueTable, because channel destroyed\", topic); } } } } finally { //最后进行解锁操作 this.lock.writeLock().unlock(); } } catch (Exception e) { log.error(\"onChannelDestroy Exception\", e); } } } 可以看到每当有broker下线时，整个路由信息都会通过加锁的方式进行实时更新。 在初始化了NamesrvController实例以后，下面就是调用它的初始化方法initialize()。 NamesrvController.java1234567891011121314 //读取KV配置 this.kvConfigManager.load(); //生成netty远程服务 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); //线程池初始化 this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(\"RemotingExecutorThread_\"));//注册处理类this.registerProcessor();//跳过定时线程初始化和ssl... 最后调用start()方法，其实就是netty的启动。 参考《rocketmq技术内幕》","link":"/2019/05/07/rocketmq1/"},{"title":"spring_retry","text":"spring retry原理简介spring retry可以帮助我们简化重复调用代码，不必要给每个方法编写对应的重试逻辑，避免下次维护和扩展时带来困难。 缺点使用spring retry就必须要捆版使用spring aop, 你只想在某个工具类里重试时明显使用自己的代码更加轻量，自己把重试逻辑抽离出来，完全可以按照自己想要地参数进行重试。 demo12345678910111213&lt;!-- 自己的包 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt;&lt;!-- 使用了aop --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314@SpringBootApplication@EnableRetry public class RetryDemo {}public interface RetryService { @Retryable(value = RuntimeException.class, maxAttempts = 3, backoff= @Backoff(value = 1500, maxDelay = 100000, multiplier = 1.2)) String service(String s); @Recover String recover(RuntimeException e, String s); } @EnableRetry - 表示开启重试机制 @Retryable - 表示这个方法需要重试 @Backoff - 表示重试中的退避策略,即失败的时候应该如何等待还是直接到recover @Recover - 兜底方法，即多次重试后还是失败就会执行这个方法 重试策略12345678910public interface RetryPolicy extends Serializable {// 是否可以重试boolean canRetry(RetryContext context);// 开启重试的上下文 parent是父级上下文RetryContext open(RetryContext parent);// 关闭上下文void close(RetryContext context);// 每次尝试执行失败是都会调用 Called once per retry attempt, after the callback fails.void registerThrowable(RetryContext context, Throwable throwable);} 12345678910111213141516171819202122232425262728Targets RetryPolicyImplementations of RetryPolicy (11 usages found) Value read (11 usages found) Maven: org.springframework.retry:spring-retry:1.3.3 (11 usages found) org.springframework.retry.policy (11 usages found) AlwaysRetryPolicy.java (1 usage found) 30 public class AlwaysRetryPolicy extends NeverRetryPolicy { BinaryExceptionClassifierRetryPolicy.java (1 usage found) 32 public class BinaryExceptionClassifierRetryPolicy implements RetryPolicy { CircuitBreakerRetryPolicy.java (1 usage found) 33 public class CircuitBreakerRetryPolicy implements RetryPolicy { CompositeRetryPolicy.java (1 usage found) 36 public class CompositeRetryPolicy implements RetryPolicy { ExceptionClassifierRetryPolicy (1 usage found) 105 private static class ExceptionClassifierRetryContext extends RetryContextSupport implements RetryPolicy { ExceptionClassifierRetryPolicy.java (1 usage found) 38 public class ExceptionClassifierRetryPolicy implements RetryPolicy { ExpressionRetryPolicy.java (1 usage found) 44 public class ExpressionRetryPolicy extends SimpleRetryPolicy implements BeanFactoryAware { MaxAttemptsRetryPolicy.java (1 usage found) 37 public class MaxAttemptsRetryPolicy implements RetryPolicy { NeverRetryPolicy.java (1 usage found) 31 public class NeverRetryPolicy implements RetryPolicy { SimpleRetryPolicy.java (1 usage found) 58 public class SimpleRetryPolicy implements RetryPolicy { TimeoutRetryPolicy.java (1 usage found) 31 public class TimeoutRetryPolicy implements RetryPolicy { SimpleRetryPolicy 默认最多重试3次 1.3版本后可以用CompositeRetryPolicy组合MaxAttemptsRetryPolicy 和 BinaryExceptionClassifierRetryPolicy TimeoutRetryPolicy 默认在1秒内失败都会重试 ExpressionRetryPolicy 符合表达式就会重试 CircuitBreakerRetryPolicy 增加了熔断的机制，如果不在熔断状态，则允许重试 CompositeRetryPolicy 可以组合多个重试策略 NeverRetryPolicy 从不重试（也是一种重试策略哈） AlwaysRetryPolicy 总是重试 MaxAttemptsRetryPolicy 默认最多重试3次 退避策略退避是指怎么去做下一次的重试，在这里其实就是等待多长时间 123456789101112131415public interface BackOffPolicy { /** * Start a new block of back off operations. Implementations can choose to pause when * this method is called, but normally it returns immediately. * @param context the {@link RetryContext} context, which might contain information * that we can use to decide how to proceed. * @return the implementation-specific {@link BackOffContext} or &apos;&lt;code&gt;null&lt;/code&gt;&apos;. */ BackOffContext start(RetryContext context); //怎么去做下一次的重试 /** * Back off/pause in an implementation-specific fashion. The passed in * {@link BackOffContext} corresponds to the one created by the call to {@link #start} * for a given retry operation set. * @param backOffContext the {@link BackOffContext} * @throws BackOffInterruptedException if the attempt at back off is interrupted. */ void backOff(BackOffContext backOffContext) throws BackOffInterruptedException; } 1234567891011121314151617181920Targets BackOffPolicyImplementations of BackOffPolicy (7 usages found) Value read (7 usages found) Maven: org.springframework.retry:spring-retry:1.3.3 (7 usages found) org.springframework.retry.backoff (7 usages found) ExponentialBackOffPolicy.java (1 usage found) 43 public class ExponentialBackOffPolicy implements SleepingBackOffPolicy&lt;ExponentialBackOffPolicy&gt; { ExponentialRandomBackOffPolicy.java (1 usage found) 48 public class ExponentialRandomBackOffPolicy extends ExponentialBackOffPolicy { FixedBackOffPolicy.java (1 usage found) 31 public class FixedBackOffPolicy extends StatelessBackOffPolicy implements SleepingBackOffPolicy&lt;FixedBackOffPolicy&gt; { NoBackOffPolicy.java (1 usage found) 26 public class NoBackOffPolicy extends StatelessBackOffPolicy { SleepingBackOffPolicy.java (1 usage found) 25 public interface SleepingBackOffPolicy&lt;T extends SleepingBackOffPolicy&lt;T&gt;&gt; extends BackOffPolicy { StatelessBackOffPolicy.java (1 usage found) 28 public abstract class StatelessBackOffPolicy implements BackOffPolicy { UniformRandomBackOffPolicy.java (1 usage found) 33 public class UniformRandomBackOffPolicy extends StatelessBackOffPolicy FixedBackOffPolicy 默认固定延迟1秒后执行下一次重试 ExponentialBackOffPolicy 指数递增延迟执行重试，默认初始0.1秒，系数是2，那么下次延迟0.2秒，再下次就是延迟0.4秒，如此类推，最大30秒。 ExponentialRandomBackOffPolicy 在上面那个策略上增加随机性 UniformRandomBackOffPolicy 这个跟上面的区别就是，上面的延迟会不停递增，这个只会在固定的区间随机 StatelessBackOffPolicy 这个说明是无状态的，所谓无状态就是对上次的退避无感知，从它下面的子类也能看出来 这个类在个抽象类 实现类是NoBackOffPolicy 原理@EnableRetry 这个注解主要使用了@EnableAspectJAutoProxy(proxyTargetClass = false)和@Import(RetryConfiguration.class)，就是打开Spring AOP功能和扫描了RetryConfiguration。 RetryConfiguration是一个AbstractPointcutAdvisor，它有一个pointcut和一个advice。我们知道，在IOC过程中会根据PointcutAdvisor类来对Bean进行Pointcut的过滤，然后生成对应的AOP代理类，用advice来加强处理。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Override public void afterPropertiesSet() throws Exception { this.retryContextCache = findBean(RetryContextCache.class); this.methodArgumentsKeyGenerator = findBean(MethodArgumentsKeyGenerator.class); this.newMethodArgumentsIdentifier = findBean(NewMethodArgumentsIdentifier.class); this.retryListeners = findBeans(RetryListener.class); this.sleeper = findBean(Sleeper.class); Set&lt;Class&lt;? extends Annotation&gt;&gt; retryableAnnotationTypes = new LinkedHashSet&lt;Class&lt;? extends Annotation&gt;&gt;(1); // 查找基于Retryable注解的类或者方法 retryableAnnotationTypes.add(Retryable.class); this.pointcut = buildPointcut(retryableAnnotationTypes); this.advice = buildAdvice(); if (this.advice instanceof BeanFactoryAware) { ((BeanFactoryAware) this.advice).setBeanFactory(this.beanFactory); } }protected Pointcut buildPointcut(Set&lt;Class&lt;? extends Annotation&gt;&gt; retryAnnotationTypes) { ComposablePointcut result = null; for (Class&lt;? extends Annotation&gt; retryAnnotationType : retryAnnotationTypes) { Pointcut filter = new AnnotationClassOrMethodPointcut(retryAnnotationType); if (result == null) { result = new ComposablePointcut(filter); } else { result.union(filter); } } return result; }protected Advice buildAdvice() { AnnotationAwareRetryOperationsInterceptor interceptor = new AnnotationAwareRetryOperationsInterceptor(); if (this.retryContextCache != null) { interceptor.setRetryContextCache(this.retryContextCache); } if (this.retryListeners != null) { interceptor.setListeners(this.retryListeners); } if (this.methodArgumentsKeyGenerator != null) { interceptor.setKeyGenerator(this.methodArgumentsKeyGenerator); } if (this.newMethodArgumentsIdentifier != null) { interceptor.setNewItemIdentifier(this.newMethodArgumentsIdentifier); } if (this.sleeper != null) { interceptor.setSleeper(this.sleeper); } return interceptor; } AnnotationAwareRetryOperationsInterceptorAnnotationAwareRetryOperationsInterceptor实现了IntroductionInterceptor ，IntroductionInterceptor又继承了MethodInterceptor。他会对符合条件的方法做增强。 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Override public Object invoke(MethodInvocation invocation) throws Throwable { MethodInterceptor delegate = getDelegate(invocation.getThis(), invocation.getMethod()); if (delegate != null) { return delegate.invoke(invocation); } else { return invocation.proceed(); } }private MethodInterceptor getDelegate(Object target, Method method) { ConcurrentMap&lt;Method, MethodInterceptor&gt; cachedMethods = this.delegates.get(target); if (cachedMethods == null) { cachedMethods = new ConcurrentHashMap&lt;Method, MethodInterceptor&gt;(); } MethodInterceptor delegate = cachedMethods.get(method); if (delegate == null) { MethodInterceptor interceptor = NULL_INTERCEPTOR; Retryable retryable = AnnotatedElementUtils.findMergedAnnotation(method, Retryable.class); if (retryable == null) { retryable = AnnotatedElementUtils.findMergedAnnotation(method.getDeclaringClass(), Retryable.class); } if (retryable == null) { retryable = findAnnotationOnTarget(target, method, Retryable.class); } if (retryable != null) { //支持自定义MethodInterceptor，而且优先级最高 if (StringUtils.hasText(retryable.interceptor())) { interceptor = this.beanFactory.getBean(retryable.interceptor(), MethodInterceptor.class); } else if (retryable.stateful()) { interceptor = getStatefulInterceptor(target, method, retryable); } else { interceptor = getStatelessInterceptor(target, method, retryable); } } cachedMethods.putIfAbsent(method, interceptor); delegate = cachedMethods.get(method); } this.delegates.putIfAbsent(target, cachedMethods); return delegate == NULL_INTERCEPTOR ? null : delegate; } 接着看 getStatefulInterceptor方法123456789101112131415161718192021222324252627282930private MethodInterceptor getStatefulInterceptor(Object target, Method method, Retryable retryable) { RetryTemplate template = createTemplate(retryable.listeners()); template.setRetryContextCache(this.retryContextCache); CircuitBreaker circuit = AnnotatedElementUtils.findMergedAnnotation(method, CircuitBreaker.class); if (circuit == null) { circuit = findAnnotationOnTarget(target, method, CircuitBreaker.class); } if (circuit != null) { RetryPolicy policy = getRetryPolicy(circuit); CircuitBreakerRetryPolicy breaker = new CircuitBreakerRetryPolicy(policy); breaker.setOpenTimeout(getOpenTimeout(circuit)); breaker.setResetTimeout(getResetTimeout(circuit)); template.setRetryPolicy(breaker); template.setBackOffPolicy(new NoBackOffPolicy()); String label = circuit.label(); if (!StringUtils.hasText(label)) { label = method.toGenericString(); } return RetryInterceptorBuilder.circuitBreaker().keyGenerator(new FixedKeyGenerator(&quot;circuit&quot;)) .retryOperations(template).recoverer(getRecoverer(target, method)).label(label).build(); } RetryPolicy policy = getRetryPolicy(retryable); template.setRetryPolicy(policy); template.setBackOffPolicy(getBackoffPolicy(retryable.backoff())); String label = retryable.label(); return RetryInterceptorBuilder.stateful().keyGenerator(this.methodArgumentsKeyGenerator) .newMethodArgumentsIdentifier(this.newMethodArgumentsIdentifier).retryOperations(template).label(label) .recoverer(getRecoverer(target, method)).build(); } 这里出现了一个CircuitBreaker注解，其实就是@Retryable(stateful = true)方法最终返回了一个MethodInterceptor，这里假设stateful = true 那么最后就会返回一个StatefulRetryOperationsInterceptor，这个MethodInterceptor看一下他的invoke方法。 1234567891011121314151617181920212223242526272829@Override public Object invoke(final MethodInvocation invocation) throws Throwable { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Executing proxied method in stateful retry: &quot; + invocation.getStaticPart() + &quot;(&quot; + ObjectUtils.getIdentityHexString(invocation) + &quot;)&quot;); } Object[] args = invocation.getArguments(); Object defaultKey = Arrays.asList(args); if (args.length == 1) { defaultKey = args[0]; } Object key = createKey(invocation, defaultKey); RetryState retryState = new DefaultRetryState(key, this.newMethodArgumentsIdentifier != null &amp;&amp; this.newMethodArgumentsIdentifier.isNew(args), this.rollbackClassifier); Object result = this.retryOperations.execute(new StatefulMethodInvocationRetryCallback(invocation, label), this.recoverer != null ? new ItemRecovererCallback(args, this.recoverer) : null, retryState); if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Exiting proxied method in stateful retry with result: (&quot; + result + &quot;)&quot;); } return result; } 最后的结果是retryOperations的excute方法获取的，而这个retryOperations就是上面生成的RetryTemplate。这个excute 方法里就会根据我们设置的不同策略来执行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118protected &lt;T, E extends Throwable&gt; T doExecute(RetryCallback&lt;T, E&gt; retryCallback, RecoveryCallback&lt;T&gt; recoveryCallback, RetryState state) throws E, ExhaustedRetryException { RetryPolicy retryPolicy = this.retryPolicy; BackOffPolicy backOffPolicy = this.backOffPolicy; // Allow the retry policy to initialise itself... RetryContext context = open(retryPolicy, state); if (this.logger.isTraceEnabled()) { this.logger.trace(&quot;RetryContext retrieved: &quot; + context); } // Make sure the context is available globally for clients who need // it... RetrySynchronizationManager.register(context); Throwable lastException = null; boolean exhausted = false; try { // Give clients a chance to enhance the context... boolean running = doOpenInterceptors(retryCallback, context); if (!running) { throw new TerminatedRetryException(&quot;Retry terminated abnormally by interceptor before first attempt&quot;); } // Get or Start the backoff context... BackOffContext backOffContext = null; Object resource = context.getAttribute(&quot;backOffContext&quot;); if (resource instanceof BackOffContext) { backOffContext = (BackOffContext) resource; } if (backOffContext == null) { backOffContext = backOffPolicy.start(context); if (backOffContext != null) { context.setAttribute(&quot;backOffContext&quot;, backOffContext); } } /* * We allow the whole loop to be skipped if the policy or context already * forbid the first try. This is used in the case of external retry to allow a * recovery in handleRetryExhausted without the callback processing (which * would throw an exception). */ while (canRetry(retryPolicy, context) &amp;&amp; !context.isExhaustedOnly()) { try { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Retry: count=&quot; + context.getRetryCount()); } // Reset the last exception, so if we are successful // the close interceptors will not think we failed... lastException = null; return retryCallback.doWithRetry(context); } catch (Throwable e) { lastException = e; try { registerThrowable(retryPolicy, state, context, e); } catch (Exception ex) { throw new TerminatedRetryException(&quot;Could not register throwable&quot;, ex); } finally { doOnErrorInterceptors(retryCallback, context, e); } if (canRetry(retryPolicy, context) &amp;&amp; !context.isExhaustedOnly()) { try { backOffPolicy.backOff(backOffContext); } catch (BackOffInterruptedException ex) { lastException = e; // back off was prevented by another thread - fail the retry if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Abort retry because interrupted: count=&quot; + context.getRetryCount()); } throw ex; } } if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Checking for rethrow: count=&quot; + context.getRetryCount()); } if (shouldRethrow(retryPolicy, context, state)) { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Rethrow in retry for policy: count=&quot; + context.getRetryCount()); } throw RetryTemplate.&lt;E&gt;wrapIfNecessary(e); } } /* * A stateful attempt that can retry may rethrow the exception before now, * but if we get this far in a stateful retry there&apos;s a reason for it, * like a circuit breaker or a rollback classifier. */ if (state != null &amp;&amp; context.hasAttribute(GLOBAL_STATE)) { break; } } if (state == null &amp;&amp; this.logger.isDebugEnabled()) { this.logger.debug(&quot;Retry failed last attempt: count=&quot; + context.getRetryCount()); } exhausted = true; return handleRetryExhausted(recoveryCallback, context, state); } catch (Throwable e) { throw RetryTemplate.&lt;E&gt;wrapIfNecessary(e); } finally { close(retryPolicy, context, state, lastException == null || exhausted); doCloseInterceptors(retryCallback, context, lastException); RetrySynchronizationManager.clear(); } } getRetryPolicy 和getBackoffPolicy 策略类获取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104private RetryPolicy getRetryPolicy(Annotation retryable) { Map&lt;String, Object&gt; attrs = AnnotationUtils.getAnnotationAttributes(retryable); @SuppressWarnings(&quot;unchecked&quot;) Class&lt;? extends Throwable&gt;[] includes = (Class&lt;? extends Throwable&gt;[]) attrs.get(&quot;value&quot;); String exceptionExpression = (String) attrs.get(&quot;exceptionExpression&quot;); boolean hasExpression = StringUtils.hasText(exceptionExpression); if (includes.length == 0) { @SuppressWarnings(&quot;unchecked&quot;) Class&lt;? extends Throwable&gt;[] value = (Class&lt;? extends Throwable&gt;[]) attrs.get(&quot;include&quot;); includes = value; } @SuppressWarnings(&quot;unchecked&quot;) Class&lt;? extends Throwable&gt;[] excludes = (Class&lt;? extends Throwable&gt;[]) attrs.get(&quot;exclude&quot;); Integer maxAttempts = (Integer) attrs.get(&quot;maxAttempts&quot;); String maxAttemptsExpression = (String) attrs.get(&quot;maxAttemptsExpression&quot;); if (StringUtils.hasText(maxAttemptsExpression)) { if (ExpressionRetryPolicy.isTemplate(maxAttemptsExpression)) { maxAttempts = PARSER.parseExpression(resolve(maxAttemptsExpression), PARSER_CONTEXT) .getValue(this.evaluationContext, Integer.class); } else { maxAttempts = PARSER.parseExpression(resolve(maxAttemptsExpression)).getValue(this.evaluationContext, Integer.class); } } if (includes.length == 0 &amp;&amp; excludes.length == 0) { SimpleRetryPolicy simple = hasExpression ? new ExpressionRetryPolicy(resolve(exceptionExpression)).withBeanFactory(this.beanFactory) : new SimpleRetryPolicy(); simple.setMaxAttempts(maxAttempts); return simple; } Map&lt;Class&lt;? extends Throwable&gt;, Boolean&gt; policyMap = new HashMap&lt;Class&lt;? extends Throwable&gt;, Boolean&gt;(); for (Class&lt;? extends Throwable&gt; type : includes) { policyMap.put(type, true); } for (Class&lt;? extends Throwable&gt; type : excludes) { policyMap.put(type, false); } boolean retryNotExcluded = includes.length == 0; if (hasExpression) { return new ExpressionRetryPolicy(maxAttempts, policyMap, true, exceptionExpression, retryNotExcluded) .withBeanFactory(this.beanFactory); } else { return new SimpleRetryPolicy(maxAttempts, policyMap, true, retryNotExcluded); } }private BackOffPolicy getBackoffPolicy(Backoff backoff) { Map&lt;String, Object&gt; attrs = AnnotationUtils.getAnnotationAttributes(backoff); long min = backoff.delay() == 0 ? backoff.value() : backoff.delay(); String delayExpression = (String) attrs.get(&quot;delayExpression&quot;); if (StringUtils.hasText(delayExpression)) { if (ExpressionRetryPolicy.isTemplate(delayExpression)) { min = PARSER.parseExpression(resolve(delayExpression), PARSER_CONTEXT).getValue(this.evaluationContext, Long.class); } else { min = PARSER.parseExpression(resolve(delayExpression)).getValue(this.evaluationContext, Long.class); } } long max = backoff.maxDelay(); String maxDelayExpression = (String) attrs.get(&quot;maxDelayExpression&quot;); if (StringUtils.hasText(maxDelayExpression)) { if (ExpressionRetryPolicy.isTemplate(maxDelayExpression)) { max = PARSER.parseExpression(resolve(maxDelayExpression), PARSER_CONTEXT) .getValue(this.evaluationContext, Long.class); } else { max = PARSER.parseExpression(resolve(maxDelayExpression)).getValue(this.evaluationContext, Long.class); } } double multiplier = backoff.multiplier(); String multiplierExpression = (String) attrs.get(&quot;multiplierExpression&quot;); if (StringUtils.hasText(multiplierExpression)) { if (ExpressionRetryPolicy.isTemplate(multiplierExpression)) { multiplier = PARSER.parseExpression(resolve(multiplierExpression), PARSER_CONTEXT) .getValue(this.evaluationContext, Double.class); } else { multiplier = PARSER.parseExpression(resolve(multiplierExpression)).getValue(this.evaluationContext, Double.class); } } boolean isRandom = false; if (multiplier &gt; 0) { isRandom = backoff.random(); String randomExpression = (String) attrs.get(&quot;randomExpression&quot;); if (StringUtils.hasText(randomExpression)) { if (ExpressionRetryPolicy.isTemplate(randomExpression)) { isRandom = PARSER.parseExpression(resolve(randomExpression), PARSER_CONTEXT) .getValue(this.evaluationContext, Boolean.class); } else { isRandom = PARSER.parseExpression(resolve(randomExpression)).getValue(this.evaluationContext, Boolean.class); } } } return BackOffPolicyBuilder.newBuilder().delay(min).maxDelay(max).multiplier(multiplier).random(isRandom) .sleeper(this.sleeper).build(); } 总结Spring Retry通过AOP机制来实现对业务代码的重试”入侵“，RetryTemplate中包含了核心的重试逻辑，还提供了丰富的重试策略和退避策略。 参考资料http://www.10tiao.com/html/164/201705/2652898434/1.html https://www.jianshu.com/p/58e753ca0151https://paper.tuisec.win/detail/90bd660fad9218","link":"/2022/05/07/spring_retry/"}],"tags":[{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"fastdfs","slug":"fastdfs","link":"/tags/fastdfs/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"spring security","slug":"spring-security","link":"/tags/spring-security/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"jdk","slug":"jdk","link":"/tags/jdk/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"rocketmq","slug":"rocketmq","link":"/tags/rocketmq/"}],"categories":[{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"fastdfs","slug":"fastdfs","link":"/categories/fastdfs/"},{"name":"k8s","slug":"k8s","link":"/categories/k8s/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"jdk","slug":"jdk","link":"/categories/jdk/"},{"name":"dubbo","slug":"dubbo","link":"/categories/dubbo/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"rocketmq","slug":"rocketmq","link":"/categories/rocketmq/"}]}